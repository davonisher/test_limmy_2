{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "870ea59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'/Users/macbook/Downloads/exports_10-07-2025 3/10-07-2025_ranking_2025-05-01 00:00:00_2025-05-01 00:00:00.xlsx'\n",
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "ranking_file = '/Users/macbook/Downloads/exports_10-07-2025 3/10-07-2025_ranking_2025-05-01 00:00:00_2025-05-01 00:00:00.xlsx'\n",
    "profile_file = '/Users/macbook/Downloads/exports_10-07-2025 3/10-07-2025_profile_2025-05-01 00:00:00_2025-05-01 00:00:00.xlsx'\n",
    "\n",
    "# Read Excel files\n",
    "df_ranking = pd.read_excel(ranking_file)\n",
    "df_profile = pd.read_excel(profile_file)\n",
    "\n",
    "# Combine on 'tool_id'\n",
    "df_merged = pd.merge(df_ranking, df_profile, on='tool_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c153425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tool_id</th>\n",
       "      <th>use_original</th>\n",
       "      <th>use_aggregated</th>\n",
       "      <th>name_tool</th>\n",
       "      <th>tool_url_y</th>\n",
       "      <th>tool_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>744</td>\n",
       "      <td>;prototype development;ui/ux design &amp; optimiza...</td>\n",
       "      <td>prototype development;ui/ux design &amp; optimizat...</td>\n",
       "      <td>Figma</td>\n",
       "      <td>figma.com</td>\n",
       "      <td>Figma is a collaborative design platform enabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12052</td>\n",
       "      <td>;data analysis;data visualization;data governance</td>\n",
       "      <td>;data analysis;data visualization;data governance</td>\n",
       "      <td>DataBricks</td>\n",
       "      <td>databricks.com</td>\n",
       "      <td>Databricks offers an integrated platform for d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12057</td>\n",
       "      <td>;foundation models (llm)</td>\n",
       "      <td>foundation models (llm)</td>\n",
       "      <td>Grok</td>\n",
       "      <td>x.ai</td>\n",
       "      <td>Grok-2 offers advanced conversational AI and p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6660</td>\n",
       "      <td>;foundation models (llm)</td>\n",
       "      <td>foundation models (llm)</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>chatgpt.com</td>\n",
       "      <td>Multimodal chat service exposes large language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>778</td>\n",
       "      <td>;payroll management;compliance management;cont...</td>\n",
       "      <td>payroll management;compliance management;contr...</td>\n",
       "      <td>Deel</td>\n",
       "      <td>deel.com</td>\n",
       "      <td>Deel provides a comprehensive platform for glo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tool_id                                       use_original  \\\n",
       "0      744  ;prototype development;ui/ux design & optimiza...   \n",
       "1    12052  ;data analysis;data visualization;data governance   \n",
       "2    12057                           ;foundation models (llm)   \n",
       "3     6660                           ;foundation models (llm)   \n",
       "4      778  ;payroll management;compliance management;cont...   \n",
       "\n",
       "                                      use_aggregated   name_tool  \\\n",
       "0  prototype development;ui/ux design & optimizat...       Figma   \n",
       "1  ;data analysis;data visualization;data governance  DataBricks   \n",
       "2                            foundation models (llm)        Grok   \n",
       "3                            foundation models (llm)     ChatGPT   \n",
       "4  payroll management;compliance management;contr...        Deel   \n",
       "\n",
       "       tool_url_y                                   tool_description  \n",
       "0       figma.com  Figma is a collaborative design platform enabl...  \n",
       "1  databricks.com  Databricks offers an integrated platform for d...  \n",
       "2            x.ai  Grok-2 offers advanced conversational AI and p...  \n",
       "3     chatgpt.com  Multimodal chat service exposes large language...  \n",
       "4        deel.com  Deel provides a comprehensive platform for glo...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the specified columns: tool_id, use_original, use aggreagted, name_tool\n",
    "# Note: column names are case-sensitive and may need to be adjusted if they differ in the actual DataFrame\n",
    "columns_to_keep = ['tool_id', 'use_original', 'use_aggregated', 'name_tool', 'tool_url_y', 'tool_description']\n",
    "df_selected = df_merged[columns_to_keep]\n",
    "df_selected.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15a699f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tools whose name ends with 'ai': 3645\n"
     ]
    }
   ],
   "source": [
    "# Count how many tool names end with 'ai' (case-insensitive)\n",
    "num_tools_end_with_ai = df_merged['name_tool'].dropna().apply(lambda x: str(x).strip().lower().endswith('ai')).sum()\n",
    "print(f\"Number of tools whose name ends with 'ai': {num_tools_end_with_ai}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8d2b08a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_merged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lz/910twyk903nb6sxfgz54bngc0000gn/T/ipykernel_85392/3051739048.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_merged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_merged' is not defined"
     ]
    }
   ],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a8de8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tool_id</th>\n",
       "      <th>use_original</th>\n",
       "      <th>use_aggregated</th>\n",
       "      <th>name_tool</th>\n",
       "      <th>tool_url_y</th>\n",
       "      <th>tool_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>744</td>\n",
       "      <td>;prototype development;ui/ux design &amp; optimiza...</td>\n",
       "      <td>prototype development;ui/ux design &amp; optimizat...</td>\n",
       "      <td>Figma</td>\n",
       "      <td>figma.com</td>\n",
       "      <td>Figma is a collaborative design platform enabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12052</td>\n",
       "      <td>;data analysis;data visualization;data governance</td>\n",
       "      <td>;data analysis;data visualization;data governance</td>\n",
       "      <td>DataBricks</td>\n",
       "      <td>databricks.com</td>\n",
       "      <td>Databricks offers an integrated platform for d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12057</td>\n",
       "      <td>;foundation models (llm)</td>\n",
       "      <td>foundation models (llm)</td>\n",
       "      <td>Grok</td>\n",
       "      <td>x.ai</td>\n",
       "      <td>Grok-2 offers advanced conversational AI and p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6660</td>\n",
       "      <td>;foundation models (llm)</td>\n",
       "      <td>foundation models (llm)</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>chatgpt.com</td>\n",
       "      <td>Multimodal chat service exposes large language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>778</td>\n",
       "      <td>;payroll management;compliance management;cont...</td>\n",
       "      <td>payroll management;compliance management;contr...</td>\n",
       "      <td>Deel</td>\n",
       "      <td>deel.com</td>\n",
       "      <td>Deel provides a comprehensive platform for glo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tool_id                                       use_original  \\\n",
       "0      744  ;prototype development;ui/ux design & optimiza...   \n",
       "1    12052  ;data analysis;data visualization;data governance   \n",
       "2    12057                           ;foundation models (llm)   \n",
       "3     6660                           ;foundation models (llm)   \n",
       "4      778  ;payroll management;compliance management;cont...   \n",
       "\n",
       "                                      use_aggregated   name_tool  \\\n",
       "0  prototype development;ui/ux design & optimizat...       Figma   \n",
       "1  ;data analysis;data visualization;data governance  DataBricks   \n",
       "2                            foundation models (llm)        Grok   \n",
       "3                            foundation models (llm)     ChatGPT   \n",
       "4  payroll management;compliance management;contr...        Deel   \n",
       "\n",
       "       tool_url_y                                   tool_description  \n",
       "0       figma.com  Figma is a collaborative design platform enabl...  \n",
       "1  databricks.com  Databricks offers an integrated platform for d...  \n",
       "2            x.ai  Grok-2 offers advanced conversational AI and p...  \n",
       "3     chatgpt.com  Multimodal chat service exposes large language...  \n",
       "4        deel.com  Deel provides a comprehensive platform for glo...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the specified columns: tool_id, use_original, use aggreagted, name_tool\n",
    "# Note: column names are case-sensitive and may need to be adjusted if they differ in the actual DataFrame\n",
    "columns_to_keep = ['tool_id', 'use_original', 'use_aggregated', 'name_tool', 'tool_url_y', 'tool_description']\n",
    "df_selected = df_merged[columns_to_keep]\n",
    "df_selected.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b5f95a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19238 entries, 0 to 19237\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   tool_id           19238 non-null  int64 \n",
      " 1   use_original      11537 non-null  object\n",
      " 2   use_aggregated    11339 non-null  object\n",
      " 3   name_tool         19238 non-null  object\n",
      " 4   tool_url_y        19238 non-null  object\n",
      " 5   tool_description  13568 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 901.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_selected.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a2435ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tool_id</th>\n",
       "      <th>use_original</th>\n",
       "      <th>use_aggregated</th>\n",
       "      <th>name_tool</th>\n",
       "      <th>tool_url_y</th>\n",
       "      <th>tool_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13988</th>\n",
       "      <td>16588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IELTS Podcast</td>\n",
       "      <td>essaycheck.ieltspodcast.co</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10570</th>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Altera AI</td>\n",
       "      <td>altera.ai</td>\n",
       "      <td>Altera creates digital human beings with AI ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13499</th>\n",
       "      <td>22566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FILL GENIUS</td>\n",
       "      <td>fillgenius.com</td>\n",
       "      <td>FILL GENIUS automates the process of completin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14703</th>\n",
       "      <td>20021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>StoryDiffusion AI</td>\n",
       "      <td>storydiffusion.org</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>21453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Fabricant</td>\n",
       "      <td>thefabricant.ai</td>\n",
       "      <td>Digital‑fashion house creating 3D garments, NF...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tool_id use_original use_aggregated          name_tool  \\\n",
       "13988    16588          NaN            NaN      IELTS Podcast   \n",
       "10570      100          NaN            NaN          Altera AI   \n",
       "13499    22566          NaN            NaN        FILL GENIUS   \n",
       "14703    20021          NaN            NaN  StoryDiffusion AI   \n",
       "4745     21453          NaN            NaN      The Fabricant   \n",
       "\n",
       "                       tool_url_y  \\\n",
       "13988  essaycheck.ieltspodcast.co   \n",
       "10570                   altera.ai   \n",
       "13499              fillgenius.com   \n",
       "14703          storydiffusion.org   \n",
       "4745              thefabricant.ai   \n",
       "\n",
       "                                        tool_description  \n",
       "13988                                                NaN  \n",
       "10570  Altera creates digital human beings with AI ar...  \n",
       "13499  FILL GENIUS automates the process of completin...  \n",
       "14703                                                NaN  \n",
       "4745   Digital‑fashion house creating 3D garments, NF...  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find a couple of rows where 'use_original' and 'use_aggregated' are different\n",
    "diff_rows = df_selected[df_selected['use_original'] != df_selected['use_aggregated']]\n",
    "# Display the first few such rows\n",
    "diff_rows.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6056dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List, Optional, Union\n",
    "import pandas as pd\n",
    "\n",
    "def filter_by_keywords(\n",
    "    df: pd.DataFrame,\n",
    "    column: str,\n",
    "    keywords: List[str],\n",
    "    case_sensitive: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter DataFrame rows where the specified column contains any of the given keywords.\n",
    "    \"\"\"\n",
    "    def contains_keywords(text):\n",
    "        if not isinstance(text, str):\n",
    "            return False\n",
    "        text_cmp = text if case_sensitive else text.lower()\n",
    "        kw_list = keywords if case_sensitive else [kw.lower() for kw in keywords]\n",
    "        return any(kw in text_cmp for kw in kw_list)\n",
    "    return df[df[column].apply(contains_keywords)]\n",
    "\n",
    "def remove_keywords_from_column(\n",
    "    df: pd.DataFrame,\n",
    "    column: str,\n",
    "    keywords: List[str],\n",
    "    tool_ids: Optional[List[int]] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove specified keywords from a column, optionally only for certain tool_ids.\n",
    "    \"\"\"\n",
    "    def remove_keywords(text):\n",
    "        if not isinstance(text, str):\n",
    "            return text\n",
    "        result = text\n",
    "        for kw in keywords:\n",
    "            # Remove keyword with or without leading/trailing semicolons and extra spaces\n",
    "            result = result.replace(f\";{kw}\", \"\")\n",
    "            result = result.replace(f\"{kw};\", \"\")\n",
    "            result = result.replace(kw, \"\")\n",
    "        # Clean up any accidental double semicolons or leading/trailing semicolons\n",
    "        result = result.replace(\";;\", \";\").strip(\";\").strip()\n",
    "        return result\n",
    "\n",
    "    mask = df['tool_id'].isin(tool_ids) if tool_ids is not None else pd.Series([True]*len(df), index=df.index)\n",
    "    df.loc[mask, column] = df.loc[mask, column].apply(remove_keywords)\n",
    "    return df\n",
    "\n",
    "def add_missing_tool_ids(\n",
    "    filtered_df: pd.DataFrame,\n",
    "    df_selected: pd.DataFrame,\n",
    "    tool_ids_to_add: List[int]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add rows from df_selected to filtered_df for tool_ids not already present.\n",
    "    \"\"\"\n",
    "    existing_tool_ids = set(filtered_df['tool_id'])\n",
    "    missing_tool_ids = [tid for tid in tool_ids_to_add if tid not in existing_tool_ids]\n",
    "    missing_rows = df_selected[df_selected['tool_id'].isin(missing_tool_ids)]\n",
    "    return pd.concat([filtered_df, missing_rows], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4532305e",
   "metadata": {},
   "source": [
    "### Software development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cddb37e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all rows where 'use_original' contains any of the specified keywords\n",
    "keywords = [\n",
    "    'app development',\n",
    "    'software development',\n",
    "    'website development',\n",
    "]\n",
    "\n",
    "def contains_keywords_use_original(text):\n",
    "    text = str(text).lower()\n",
    "    return any(keyword in text for keyword in keywords)\n",
    "\n",
    "# Filter the DataFrame for relevant rows\n",
    "filtered_df = df_selected[df_selected['use_original'].apply(contains_keywords_use_original)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a3ec0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 37 entries, 166 to 17122\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   tool_id           37 non-null     int64 \n",
      " 1   use_original      33 non-null     object\n",
      " 2   use_aggregated    33 non-null     object\n",
      " 3   name_tool         37 non-null     object\n",
      " 4   tool_url_x        37 non-null     object\n",
      " 5   tool_description  37 non-null     object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 2.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Find all rows where 'tool_description' contains 'software development' (case-insensitive)\n",
    "desc_mask = df_selected['tool_description'].astype(str).str.lower().str.contains('app development', na=False)\n",
    "desc_software_dev_df = df_selected[desc_mask]\n",
    "\n",
    "# Display the first few such rows\n",
    "desc_software_dev_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8a22f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tool_ids to add if not already in filtered_df\n",
    "tool_ids_to_add = [\n",
    "    13653, 13360, 6052, 15514, 5467, 13189, 11563, 4853, 8901, 5013, 9134, 1843,\n",
    "    10731, 19342, 6126, 1385, 469, 19680, 11257, 1474, 8419\n",
    "]\n",
    "\n",
    "# Find which tool_ids are not already in filtered_df\n",
    "existing_tool_ids = set(filtered_df['tool_id'])\n",
    "missing_tool_ids = [tid for tid in tool_ids_to_add if tid not in existing_tool_ids]\n",
    "\n",
    "# Get the rows from df_selected for these missing tool_ids\n",
    "missing_rows = df_selected[df_selected['tool_id'].isin(missing_tool_ids)]\n",
    "\n",
    "# Append these rows to filtered_df\n",
    "filtered_df = pd.concat([filtered_df, missing_rows], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4742c07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filtered_df to Excel file\n",
    "desc_software_dev_df.to_excel('filtered_software_development_tools.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2588d353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299 entries, 0 to 298\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   tool_id           299 non-null    int64 \n",
      " 1   use_original      297 non-null    object\n",
      " 2   use_aggregated    297 non-null    object\n",
      " 3   name_tool         299 non-null    object\n",
      " 4   tool_url_x        299 non-null    object\n",
      " 5   tool_description  298 non-null    object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 14.1+ KB\n"
     ]
    }
   ],
   "source": [
    "filtered_df.sample(5)\n",
    "filtered_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21714600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tool_id</th>\n",
       "      <th>use_original</th>\n",
       "      <th>use_aggregated</th>\n",
       "      <th>name_tool</th>\n",
       "      <th>tool_url_x</th>\n",
       "      <th>tool_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>744</td>\n",
       "      <td>;prototype development;ui/ux design &amp; optimiza...</td>\n",
       "      <td>prototype development;ui/ux design &amp; optimizat...</td>\n",
       "      <td>Figma</td>\n",
       "      <td>https://figma.com</td>\n",
       "      <td>Figma is a collaborative design platform enabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12052</td>\n",
       "      <td>;data analysis;data visualization;data governance</td>\n",
       "      <td>data analysis;data visualization;data governan...</td>\n",
       "      <td>DataBricks</td>\n",
       "      <td>https://databricks.com</td>\n",
       "      <td>Databricks offers an integrated platform for d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12057</td>\n",
       "      <td>;foundation models (llm)</td>\n",
       "      <td>foundation models (llm);software development</td>\n",
       "      <td>Grok</td>\n",
       "      <td>https://x.ai</td>\n",
       "      <td>Grok-2 offers advanced conversational AI and p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6660</td>\n",
       "      <td>;foundation models (llm)</td>\n",
       "      <td>foundation models (llm);software development</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>https://chatgpt.com</td>\n",
       "      <td>Multimodal chat service exposes large language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>778</td>\n",
       "      <td>;payroll management;compliance management;cont...</td>\n",
       "      <td>payroll management;compliance management;contr...</td>\n",
       "      <td>Deel</td>\n",
       "      <td>https://deel.com</td>\n",
       "      <td>Deel provides a comprehensive platform for glo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tool_id                                       use_original  \\\n",
       "0      744  ;prototype development;ui/ux design & optimiza...   \n",
       "1    12052  ;data analysis;data visualization;data governance   \n",
       "2    12057                           ;foundation models (llm)   \n",
       "3     6660                           ;foundation models (llm)   \n",
       "4      778  ;payroll management;compliance management;cont...   \n",
       "\n",
       "                                      use_aggregated   name_tool  \\\n",
       "0  prototype development;ui/ux design & optimizat...       Figma   \n",
       "1  data analysis;data visualization;data governan...  DataBricks   \n",
       "2       foundation models (llm);software development        Grok   \n",
       "3       foundation models (llm);software development     ChatGPT   \n",
       "4  payroll management;compliance management;contr...        Deel   \n",
       "\n",
       "               tool_url_x                                   tool_description  \n",
       "0       https://figma.com  Figma is a collaborative design platform enabl...  \n",
       "1  https://databricks.com  Databricks offers an integrated platform for d...  \n",
       "2            https://x.ai  Grok-2 offers advanced conversational AI and p...  \n",
       "3     https://chatgpt.com  Multimodal chat service exposes large language...  \n",
       "4        https://deel.com  Deel provides a comprehensive platform for glo...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Add 'software development' to use_aggregated for these tools, if not already present\n",
    "def add_software_development(agg):\n",
    "    agg = str(agg) if pd.notnull(agg) else ''\n",
    "    # Remove leading/trailing semicolons and whitespace\n",
    "    agg_clean = agg.strip(';').strip()\n",
    "    # Check if 'software development' is already present (case-insensitive)\n",
    "    if 'software development' in agg_clean.lower().split(';'):\n",
    "        return agg_clean\n",
    "    # Add 'software development' at the end, separated by semicolon if needed\n",
    "    if agg_clean:\n",
    "        return agg_clean + ';software development'\n",
    "    else:\n",
    "        return 'software development'\n",
    "\n",
    "# Update the original df_selected DataFrame in place\n",
    "for idx in filtered_df.index:\n",
    "    current_agg = df_selected.at[idx, 'use_aggregated']\n",
    "    df_selected.at[idx, 'use_aggregated'] = add_software_development(current_agg)\n",
    "\n",
    "filtered_df = df_selected.loc[filtered_df.index]  # Refresh filtered_df with updated values\n",
    "\n",
    "filtered_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a86d05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filtered_df to Excel with 'tool_url_x' renamed to 'tool_url'\n",
    "filtered_df_to_save = filtered_df.rename(columns={'tool_url_x': 'tool_url'})\n",
    "filtered_df_to_save.to_excel('software_development_sub_ranking.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b3790c",
   "metadata": {},
   "source": [
    "### Energy management, monitoring & analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f2e23bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all rows where 'use_original' contains any of the specified keywords\n",
    "keywords = [\n",
    "\"gaming\"\n",
    "]\n",
    "\n",
    "def contains_keywords_use_original(text):\n",
    "    text = str(text).lower()\n",
    "    return any(keyword in text for keyword in keywords)\n",
    "\n",
    "# Filter the DataFrame for relevant rows\n",
    "filtered_df_energy = df_selected[df_selected['use_original'].apply(contains_keywords_use_original)]\n",
    "\n",
    "# Save filtered_df to Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "52e7bcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 34 entries, 1017 to 19234\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   tool_id           34 non-null     int64 \n",
      " 1   use_original      34 non-null     object\n",
      " 2   use_aggregated    34 non-null     object\n",
      " 3   name_tool         34 non-null     object\n",
      " 4   tool_url_x        34 non-null     object\n",
      " 5   tool_description  34 non-null     object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 1.9+ KB\n"
     ]
    }
   ],
   "source": [
    "filtered_df_energy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9c1e7c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tool_ids for which to delete the specified keywords\n",
    "tool_ids_to_edit = [3340, 13388, 3703, 11555, 14017, 5056]\n",
    "keywords_to_remove = [\n",
    "    \"energy monitoring & analysis\", \"energy management\", \"climate control\"\n",
    "]\n",
    "\n",
    "def remove_keywords_from_aggregated(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    result = text\n",
    "    for kw in keywords_to_remove:\n",
    "        # Remove keyword with or without leading/trailing semicolons and extra spaces\n",
    "        result = result.replace(f\";{kw}\", \"\")\n",
    "        result = result.replace(f\"{kw};\", \"\")\n",
    "        result = result.replace(kw, \"\")\n",
    "    # Clean up any accidental double semicolons or leading/trailing semicolons\n",
    "    result = result.replace(\";;\", \";\").strip(\";\").strip()\n",
    "    return result\n",
    "\n",
    "mask = filtered_df_energy['tool_id'].isin(tool_ids_to_edit)\n",
    "filtered_df_energy.loc[mask, 'use_aggregated'] = (\n",
    "    filtered_df_energy.loc[mask, 'use_aggregated'].apply(remove_keywords_from_aggregated)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "69008f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tool_id</th>\n",
       "      <th>use_original</th>\n",
       "      <th>use_aggregated</th>\n",
       "      <th>name_tool</th>\n",
       "      <th>tool_url_x</th>\n",
       "      <th>tool_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>12745</td>\n",
       "      <td>;energy optimization;carbon footprint analysis...</td>\n",
       "      <td>;energy optimization;carbon footprint analysis...</td>\n",
       "      <td>metron</td>\n",
       "      <td>https://metron.energy</td>\n",
       "      <td>The METRON Energy Management and Optimization ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>13057</td>\n",
       "      <td>;energy management;heating control</td>\n",
       "      <td>;energy management;heating control</td>\n",
       "      <td>Mysa</td>\n",
       "      <td>https://getmysa.com</td>\n",
       "      <td>Mysa Smart Thermostats offer control over elec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>3340</td>\n",
       "      <td>;transaction monitoring;app development;energy...</td>\n",
       "      <td>transaction monitoring;app development;pricing...</td>\n",
       "      <td>MeetFrank</td>\n",
       "      <td>https://meetfrank.com</td>\n",
       "      <td>A comprehensive platform offering remote, hybr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3982</th>\n",
       "      <td>5511</td>\n",
       "      <td>;energy optimization;compliance management;ene...</td>\n",
       "      <td>;energy optimization;compliance management;ene...</td>\n",
       "      <td>Ecoplanet</td>\n",
       "      <td>https://ecoplanet.tech</td>\n",
       "      <td>Ecoplanet offers an advanced energy management...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5857</th>\n",
       "      <td>4653</td>\n",
       "      <td>;energy monitoring &amp; analysis;energy management</td>\n",
       "      <td>;energy monitoring &amp; analysis;energy management</td>\n",
       "      <td>etalytics</td>\n",
       "      <td>https://etalytics.com</td>\n",
       "      <td>etalytics provides AI-driven energy management...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tool_id                                       use_original  \\\n",
       "1704    12745  ;energy optimization;carbon footprint analysis...   \n",
       "2232    13057                 ;energy management;heating control   \n",
       "2894     3340  ;transaction monitoring;app development;energy...   \n",
       "3982     5511  ;energy optimization;compliance management;ene...   \n",
       "5857     4653    ;energy monitoring & analysis;energy management   \n",
       "\n",
       "                                         use_aggregated  name_tool  \\\n",
       "1704  ;energy optimization;carbon footprint analysis...     metron   \n",
       "2232                 ;energy management;heating control       Mysa   \n",
       "2894  transaction monitoring;app development;pricing...  MeetFrank   \n",
       "3982  ;energy optimization;compliance management;ene...  Ecoplanet   \n",
       "5857    ;energy monitoring & analysis;energy management  etalytics   \n",
       "\n",
       "                  tool_url_x  \\\n",
       "1704   https://metron.energy   \n",
       "2232     https://getmysa.com   \n",
       "2894   https://meetfrank.com   \n",
       "3982  https://ecoplanet.tech   \n",
       "5857   https://etalytics.com   \n",
       "\n",
       "                                       tool_description  \n",
       "1704  The METRON Energy Management and Optimization ...  \n",
       "2232  Mysa Smart Thermostats offer control over elec...  \n",
       "2894  A comprehensive platform offering remote, hybr...  \n",
       "3982  Ecoplanet offers an advanced energy management...  \n",
       "5857  etalytics provides AI-driven energy management...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df_energy.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "684ef6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20 entries, 1704 to 19180\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   tool_id           20 non-null     int64 \n",
      " 1   use_original      20 non-null     object\n",
      " 2   use_aggregated    20 non-null     object\n",
      " 3   name_tool         20 non-null     object\n",
      " 4   tool_url_x        20 non-null     object\n",
      " 5   tool_description  20 non-null     object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 1.1+ KB\n"
     ]
    }
   ],
   "source": [
    "filtered_df_energy.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed2ceb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to excel\n",
    "filtered_df_energy.to_excel('filtered_energy_tools.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "092a9557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 13 entries, 1704 to 19180\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   tool_id           13 non-null     int64 \n",
      " 1   use_original      10 non-null     object\n",
      " 2   use_aggregated    10 non-null     object\n",
      " 3   name_tool         13 non-null     object\n",
      " 4   tool_url_x        13 non-null     object\n",
      " 5   tool_description  13 non-null     object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 728.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# Find all rows where 'tool_description' contains 'software development' (case-insensitive)\n",
    "desc_mask = df_selected['tool_description'].astype(str).str.lower().str.contains('energy management', na=False)\n",
    "energy_df = df_selected[desc_mask]\n",
    "\n",
    "# Display the first few such rows\n",
    "energy_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b18dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filtered_df to Excel file\n",
    "desc_software_dev_df.to_excel('filtered_software_development_tools.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7dacff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tool_ids to add if not already in filtered_df\n",
    "tool_ids_to_add = [\n",
    "    13653, 13360, 6052, 15514, 5467, 13189, 11563, 4853, 8901, 5013, 9134, 1843,\n",
    "    10731, 19342, 6126, 1385, 469, 19680, 11257, 1474, 8419\n",
    "]\n",
    "\n",
    "# Find which tool_ids are not already in filtered_df\n",
    "existing_tool_ids = set(filtered_df['tool_id'])\n",
    "missing_tool_ids = [tid for tid in tool_ids_to_add if tid not in existing_tool_ids]\n",
    "\n",
    "# Get the rows from df_selected for these missing tool_ids\n",
    "missing_rows = df_selected[df_selected['tool_id'].isin(missing_tool_ids)]\n",
    "\n",
    "# Append these rows to filtered_df\n",
    "filtered_df = pd.concat([filtered_df, missing_rows], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47239abc",
   "metadata": {},
   "source": [
    "## Gaming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "267cb321",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List, Optional, Union\n",
    "import pandas as pd\n",
    "\n",
    "def filter_by_keywords(\n",
    "    df: pd.DataFrame,\n",
    "    column: str,\n",
    "    keywords: List[str],\n",
    "    case_sensitive: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter DataFrame rows where the specified column contains any of the given keywords.\n",
    "    \"\"\"\n",
    "    def contains_keywords(text):\n",
    "        if not isinstance(text, str):\n",
    "            return False\n",
    "        text_cmp = text if case_sensitive else text.lower()\n",
    "        kw_list = keywords if case_sensitive else [kw.lower() for kw in keywords]\n",
    "        return any(kw in text_cmp for kw in kw_list)\n",
    "    return df[df[column].apply(contains_keywords)]\n",
    "\n",
    "def remove_keywords_from_column(\n",
    "    df: pd.DataFrame,\n",
    "    column: str,\n",
    "    keywords: List[str],\n",
    "    tool_ids: Optional[List[int]] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove specified keywords from a column, optionally only for certain tool_ids.\n",
    "    \"\"\"\n",
    "    def remove_keywords(text):\n",
    "        if not isinstance(text, str):\n",
    "            return text\n",
    "        result = text\n",
    "        for kw in keywords:\n",
    "            # Remove keyword with or without leading/trailing semicolons and extra spaces\n",
    "            result = result.replace(f\";{kw}\", \"\")\n",
    "            result = result.replace(f\"{kw};\", \"\")\n",
    "            result = result.replace(kw, \"\")\n",
    "        # Clean up any accidental double semicolons or leading/trailing semicolons\n",
    "        result = result.replace(\";;\", \";\").strip(\";\").strip()\n",
    "        return result\n",
    "\n",
    "    mask = df['tool_id'].isin(tool_ids) if tool_ids is not None else pd.Series([True]*len(df), index=df.index)\n",
    "    df.loc[mask, column] = df.loc[mask, column].apply(remove_keywords)\n",
    "    return df\n",
    "\n",
    "def add_missing_tool_ids(\n",
    "    filtered_df: pd.DataFrame,\n",
    "    df_selected: pd.DataFrame,\n",
    "    tool_ids_to_add: List[int]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add rows from df_selected to filtered_df for tool_ids not already present.\n",
    "    \"\"\"\n",
    "    existing_tool_ids = set(filtered_df['tool_id'])\n",
    "    missing_tool_ids = [tid for tid in tool_ids_to_add if tid not in existing_tool_ids]\n",
    "    missing_rows = df_selected[df_selected['tool_id'].isin(missing_tool_ids)]\n",
    "    return pd.concat([filtered_df, missing_rows], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ed758a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your keywords and tool_ids for any use case\n",
    "keywords = [\n",
    "    \"gaming\"\n",
    "    # Add more as needed, e.g. \"gaming\", \"software development\", etc.\n",
    "]\n",
    "#tool_ids_to_edit = [3340, 13388, 3703, 11555, 14017, 5056]  # Example tool_ids\n",
    "#keywords_to_remove = keywords  # Can be different if needed\n",
    "\n",
    "# 1. Filter by keywords in 'use_original'\n",
    "filtered_df_gaming = filter_by_keywords(df_selected, 'use_original', keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4054aee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 34 entries, 1017 to 19234\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   tool_id           34 non-null     int64 \n",
      " 1   use_original      34 non-null     object\n",
      " 2   use_aggregated    34 non-null     object\n",
      " 3   name_tool         34 non-null     object\n",
      " 4   tool_url_y        34 non-null     object\n",
      " 5   tool_description  34 non-null     object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 1.9+ KB\n"
     ]
    }
   ],
   "source": [
    "filtered_df_gaming.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c3fe50f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Remove keywords from 'use_aggregated' for certain tool_ids\n",
    "filtered_df_gaming = remove_keywords_from_column(filtered_df_gaming, 'use_aggregated', keywords_to_remove, tool_ids=tool_ids_to_edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8e0bc15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Save to Excel (filename can be parameterized)\n",
    "filtered_df_gaming.to_excel('filtered_tools.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cca5ceee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 45 entries, 47 to 19181\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   tool_id           45 non-null     int64 \n",
      " 1   use_original      31 non-null     object\n",
      " 2   use_aggregated    31 non-null     object\n",
      " 3   name_tool         45 non-null     object\n",
      " 4   tool_url_y        45 non-null     object\n",
      " 5   tool_description  45 non-null     object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 2.5+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. Filter by keywords in 'tool_description' (example: for \"software development\" or any other)\n",
    "desc_keywords = [\"gaming\"]  # Replace with e.g. [\"software development\", \"gaming\"] as needed\n",
    "desc_df = filter_by_keywords(df_selected, 'tool_description', desc_keywords)\n",
    "desc_df.info()\n",
    "\n",
    "\n",
    "# 3. Save to Excel (filename can be parameterized)\n",
    "desc_df.to_excel('filtered_tools2.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b63c49d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Add missing tool_ids to filtered_df (if needed)\n",
    "tool_ids_to_add = [\n",
    "    13653, 13360, 6052, 15514, 5467, 13189, 11563, 4853, 8901, 5013, 9134, 1843,\n",
    "    10731, 19342, 6126, 1385, 469, 19680, 11257, 1474, 8419\n",
    "]\n",
    "filtered_df_gaming = add_missing_tool_ids(filtered_df_gaming, df_selected, tool_ids_to_add)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a727ba72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55 entries, 0 to 54\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   tool_id           55 non-null     int64 \n",
      " 1   use_original      53 non-null     object\n",
      " 2   use_aggregated    53 non-null     object\n",
      " 3   name_tool         55 non-null     object\n",
      " 4   tool_url_y        55 non-null     object\n",
      " 5   tool_description  55 non-null     object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 2.7+ KB\n"
     ]
    }
   ],
   "source": [
    "filtered_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f14338c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_excel('gaming_sub_ranking.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5a252e",
   "metadata": {},
   "source": [
    "software development,\n",
    "\n",
    "\n",
    "energy monitoring & analysis, energy management, climate control\n",
    "\n",
    "gaming\n",
    "\n",
    "fashion recommendation\n",
    "\n",
    "food & drinks recommendations\n",
    "\n",
    "receipt management\n",
    "\n",
    "drone management\n",
    "\n",
    "disease detection, medical image analysis\n",
    "\n",
    "fall prevention\n",
    "\n",
    "recruiting & hiring\n",
    "\n",
    "legal assistance\n",
    "\n",
    "collision detection & avoidance ( https://www.spoor.ai/collision-detection)\n",
    "\n",
    "damage detection\n",
    "\n",
    "car damage detection\n",
    "\n",
    "travel planning\n",
    "\n",
    "# ai ethics and governance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3c4df7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your keywords and tool_ids for any use case\n",
    "keywords = [\n",
    "    \"fall prevention\"\n",
    "    # Add more as needed, e.g. \"gaming\", \"software development\", etc.\n",
    "]\n",
    "#tool_ids_to_edit = [3340, 13388, 3703, 11555, 14017, 5056]  # Example tool_ids\n",
    "#keywords_to_remove = keywords  # Can be different if needed\n",
    "\n",
    "# 1. Filter by keywords in 'use_original'\n",
    "filtered_df = filter_by_keywords(df_selected, 'use_original', keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554739b0",
   "metadata": {},
   "source": [
    "## Medical image & disease detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "42ecc45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your keywords and tool_ids for any use case\n",
    "keywords = [\n",
    "    \"medical image analysis\", \"disease detection\"\n",
    "    # Add more as needed, e.g. \"gaming\", \"software development\", etc.\n",
    "]\n",
    "tool_ids_to_edit = [6772, 3068, 10408, 13407, 8413, 7127, 1384, 1395, 24355, 6363]  # Example tool_ids\n",
    "keywords_to_remove = keywords  # Can be different if needed\n",
    "\n",
    "# 1. Filter by keywords in 'use_original'\n",
    "filtered_df = filter_by_keywords(df_selected, 'use_original', keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "08c60e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Remove keywords from 'use_aggregated' for certain tool_ids\n",
    "filtered_df = remove_keywords_from_column(filtered_df, 'use_aggregated', keywords_to_remove, tool_ids=tool_ids_to_edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "400a775b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lz/910twyk903nb6sxfgz54bngc0000gn/T/ipykernel_59086/2578463729.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['use_aggregated'] = filtered_df['use_aggregated'].str.replace(\n"
     ]
    }
   ],
   "source": [
    "# Replace 'disease detection' with 'medical disease detection' in 'use_aggregated' column of filtered_df\n",
    "filtered_df['use_aggregated'] = filtered_df['use_aggregated'].str.replace(\n",
    "    'disease detection', 'medical disease detection', regex=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6b847d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 24 entries, 354 to 19050\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   tool_id           24 non-null     int64 \n",
      " 1   use_original      17 non-null     object\n",
      " 2   use_aggregated    17 non-null     object\n",
      " 3   name_tool         24 non-null     object\n",
      " 4   tool_url_x        24 non-null     object\n",
      " 5   tool_description  24 non-null     object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 1.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# 4. Filter by keywords in 'tool_description' that are NOT in filtered_df\n",
    "desc_keywords = [\"disease\"]  # Replace with e.g. [\"software development\", \"gaming\"] as needed\n",
    "\n",
    "# Get all rows in df_selected where 'tool_description' contains any of desc_keywords\n",
    "desc_df_all = filter_by_keywords(df_selected, 'tool_description', desc_keywords)\n",
    "\n",
    "# Exclude those that are already in filtered_df (by tool_id)\n",
    "desc_df = desc_df_all[~desc_df_all['tool_id'].isin(filtered_df['tool_id'])]\n",
    "\n",
    "desc_df.info()\n",
    "\n",
    "# 3. Save to Excel (filename can be parameterized)\n",
    "desc_df.to_excel('filtered_tools3_disease.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "57b4bbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tool_id</th>\n",
       "      <th>use_original</th>\n",
       "      <th>use_aggregated</th>\n",
       "      <th>name_tool</th>\n",
       "      <th>tool_url_x</th>\n",
       "      <th>tool_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>6775</td>\n",
       "      <td>;digital &amp; ai-driven therapy;therapy managemen...</td>\n",
       "      <td>digital &amp; ai-driven therapy;therapy management...</td>\n",
       "      <td>Insitro</td>\n",
       "      <td>https://insitro.com</td>\n",
       "      <td>insitro employs machine learning to integrate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>6639</td>\n",
       "      <td>;disease detection;clinical trial management</td>\n",
       "      <td>;medical disease detection;clinical trial mana...</td>\n",
       "      <td>InSilico Medicine</td>\n",
       "      <td>https://insilico.com</td>\n",
       "      <td>PHARMA.AI integrates cutting-edge generative A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>6726</td>\n",
       "      <td>;disease detection;disease treatment;patient c...</td>\n",
       "      <td>;medical disease detection;disease treatment;p...</td>\n",
       "      <td>Viz.ai</td>\n",
       "      <td>https://viz.ai</td>\n",
       "      <td>Viz.ai offers an FDA-cleared AI-powered care c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3687</th>\n",
       "      <td>6772</td>\n",
       "      <td>;climate &amp; weather analysis;disease detection;...</td>\n",
       "      <td>climate &amp; weather analysis;farm management &amp; o...</td>\n",
       "      <td>Wolkus HQ</td>\n",
       "      <td>https://fasal.co</td>\n",
       "      <td>Fasal leverages IoT and AI to offer data-drive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4777</th>\n",
       "      <td>3068</td>\n",
       "      <td>;disease detection;climate &amp; weather analysis;...</td>\n",
       "      <td>climate &amp; weather analysis;satellite image ana...</td>\n",
       "      <td>Agrio</td>\n",
       "      <td>https://agrio.app</td>\n",
       "      <td>Agrio is an app that uses AI algorithms to pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tool_id                                       use_original  \\\n",
       "383      6775  ;digital & ai-driven therapy;therapy managemen...   \n",
       "408      6639       ;disease detection;clinical trial management   \n",
       "412      6726  ;disease detection;disease treatment;patient c...   \n",
       "3687     6772  ;climate & weather analysis;disease detection;...   \n",
       "4777     3068  ;disease detection;climate & weather analysis;...   \n",
       "\n",
       "                                         use_aggregated          name_tool  \\\n",
       "383   digital & ai-driven therapy;therapy management...            Insitro   \n",
       "408   ;medical disease detection;clinical trial mana...  InSilico Medicine   \n",
       "412   ;medical disease detection;disease treatment;p...             Viz.ai   \n",
       "3687  climate & weather analysis;farm management & o...          Wolkus HQ   \n",
       "4777  climate & weather analysis;satellite image ana...              Agrio   \n",
       "\n",
       "                tool_url_x                                   tool_description  \n",
       "383    https://insitro.com  insitro employs machine learning to integrate ...  \n",
       "408   https://insilico.com  PHARMA.AI integrates cutting-edge generative A...  \n",
       "412         https://viz.ai  Viz.ai offers an FDA-cleared AI-powered care c...  \n",
       "3687      https://fasal.co  Fasal leverages IoT and AI to offer data-drive...  \n",
       "4777     https://agrio.app  Agrio is an app that uses AI algorithms to pro...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "de4142ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 42 entries, 383 to 19104\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   tool_id           42 non-null     int64 \n",
      " 1   use_original      42 non-null     object\n",
      " 2   use_aggregated    42 non-null     object\n",
      " 3   name_tool         42 non-null     object\n",
      " 4   tool_url_x        42 non-null     object\n",
      " 5   tool_description  41 non-null     object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 2.3+ KB\n"
     ]
    }
   ],
   "source": [
    "filtered_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "21bc8733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tool_id</th>\n",
       "      <th>use_original</th>\n",
       "      <th>use_aggregated</th>\n",
       "      <th>name_tool</th>\n",
       "      <th>tool_url_x</th>\n",
       "      <th>tool_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>6775</td>\n",
       "      <td>;digital &amp; ai-driven therapy;therapy managemen...</td>\n",
       "      <td>digital &amp; ai-driven therapy;therapy management...</td>\n",
       "      <td>Insitro</td>\n",
       "      <td>https://insitro.com</td>\n",
       "      <td>insitro employs machine learning to integrate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>6639</td>\n",
       "      <td>;disease detection;clinical trial management</td>\n",
       "      <td>;medical disease detection;clinical trial mana...</td>\n",
       "      <td>InSilico Medicine</td>\n",
       "      <td>https://insilico.com</td>\n",
       "      <td>PHARMA.AI integrates cutting-edge generative A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>6726</td>\n",
       "      <td>;disease detection;disease treatment;patient c...</td>\n",
       "      <td>;medical disease detection;disease treatment;p...</td>\n",
       "      <td>Viz.ai</td>\n",
       "      <td>https://viz.ai</td>\n",
       "      <td>Viz.ai offers an FDA-cleared AI-powered care c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>13571</td>\n",
       "      <td>;disease detection;deep learning</td>\n",
       "      <td>;medical disease detection;deep learning</td>\n",
       "      <td>PMcardio</td>\n",
       "      <td>https://powerfulmedical.com</td>\n",
       "      <td>PMcardio's AI-powered platform enables rapid c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>12910</td>\n",
       "      <td>;speech recognition;natural language processin...</td>\n",
       "      <td>;speech recognition;natural language processin...</td>\n",
       "      <td>Defined.ai</td>\n",
       "      <td>https://defined.ai</td>\n",
       "      <td>Defined.ai delivers ethically sourced and high...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tool_id                                       use_original  \\\n",
       "383      6775  ;digital & ai-driven therapy;therapy managemen...   \n",
       "408      6639       ;disease detection;clinical trial management   \n",
       "412      6726  ;disease detection;disease treatment;patient c...   \n",
       "1109    13571                   ;disease detection;deep learning   \n",
       "1329    12910  ;speech recognition;natural language processin...   \n",
       "\n",
       "                                         use_aggregated          name_tool  \\\n",
       "383   digital & ai-driven therapy;therapy management...            Insitro   \n",
       "408   ;medical disease detection;clinical trial mana...  InSilico Medicine   \n",
       "412   ;medical disease detection;disease treatment;p...             Viz.ai   \n",
       "1109           ;medical disease detection;deep learning           PMcardio   \n",
       "1329  ;speech recognition;natural language processin...         Defined.ai   \n",
       "\n",
       "                       tool_url_x  \\\n",
       "383           https://insitro.com   \n",
       "408          https://insilico.com   \n",
       "412                https://viz.ai   \n",
       "1109  https://powerfulmedical.com   \n",
       "1329           https://defined.ai   \n",
       "\n",
       "                                       tool_description  \n",
       "383   insitro employs machine learning to integrate ...  \n",
       "408   PHARMA.AI integrates cutting-edge generative A...  \n",
       "412   Viz.ai offers an FDA-cleared AI-powered care c...  \n",
       "1109  PMcardio's AI-powered platform enables rapid c...  \n",
       "1329  Defined.ai delivers ethically sourced and high...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1c69af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered DataFrame to an Excel file\n",
    "filtered_df.to_excel(\"disease.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c2592775",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your keywords and tool_ids for any use case\n",
    "keywords = [\n",
    "    \"medical image analysis\", \"disease detection\"\n",
    "    # Add more as needed, e.g. \"gaming\", \"software development\", etc.\n",
    "]\n",
    "#tool_ids_to_edit = [3340, 13388, 3703, 11555, 14017, 5056]  # Example tool_ids\n",
    "#keywords_to_remove = keywords  # Can be different if needed\n",
    "\n",
    "# 1. Filter by keywords in 'use_original'\n",
    "filtered_df = filter_by_keywords(df_selected, 'use_original', keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a8f69a",
   "metadata": {},
   "source": [
    "## Background Removal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c16d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your keywords and tool_ids for any use case\n",
    "keywords = [\n",
    "    \"background removal\"\n",
    "    # Add more as needed, e.g. \"gaming\", \"software development\", etc.\n",
    "]\n",
    "#tool_ids_to_edit = [3340, 13388, 3703, 11555, 14017, 5056]  # Example tool_ids\n",
    "\n",
    "# 1. Filter by keywords in 'use_original'\n",
    "bg_removal = filter_by_keywords(df_selected, 'use_original', keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7e456c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 176 entries, 0 to 175\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   tool_id           176 non-null    int64 \n",
      " 1   use_original      173 non-null    object\n",
      " 2   use_aggregated    170 non-null    object\n",
      " 3   name_tool         176 non-null    object\n",
      " 4   tool_url_y        176 non-null    object\n",
      " 5   tool_description  176 non-null    object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 8.4+ KB\n"
     ]
    }
   ],
   "source": [
    "bg_removal.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "926283c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tool_id</th>\n",
       "      <th>use_original</th>\n",
       "      <th>use_aggregated</th>\n",
       "      <th>name_tool</th>\n",
       "      <th>tool_url_y</th>\n",
       "      <th>tool_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>13666</td>\n",
       "      <td>;image generation;background removal;logo desi...</td>\n",
       "      <td>;image generation;background removal;logo desi...</td>\n",
       "      <td>Kittl</td>\n",
       "      <td>kittl.com</td>\n",
       "      <td>Kittl is a browser-based design tool offering ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>18802</td>\n",
       "      <td>;image resizing;image color editing;background...</td>\n",
       "      <td>;image editing;image color editing;background ...</td>\n",
       "      <td>PicLumen</td>\n",
       "      <td>piclumen.com</td>\n",
       "      <td>PicLumen is an AI-driven image creation platfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>5684</td>\n",
       "      <td>;image generation;background removal;image edi...</td>\n",
       "      <td>;image generation;background removal;image edi...</td>\n",
       "      <td>Recraft</td>\n",
       "      <td>recraft.ai</td>\n",
       "      <td>Recraft offers a premium image generation and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>13467</td>\n",
       "      <td>;background removal</td>\n",
       "      <td>background removal</td>\n",
       "      <td>Remove.bg</td>\n",
       "      <td>remove.bg</td>\n",
       "      <td>remove.bg automatically removes image backgrou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>12663</td>\n",
       "      <td>;icon generation;image resizing;background rem...</td>\n",
       "      <td>;icon generation;image editing;background remo...</td>\n",
       "      <td>Icons8</td>\n",
       "      <td>icons8.com</td>\n",
       "      <td>Icons8 provides apps and tools for design, off...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tool_id                                       use_original  \\\n",
       "54     13666  ;image generation;background removal;logo desi...   \n",
       "143    18802  ;image resizing;image color editing;background...   \n",
       "152     5684  ;image generation;background removal;image edi...   \n",
       "203    13467                                ;background removal   \n",
       "241    12663  ;icon generation;image resizing;background rem...   \n",
       "\n",
       "                                        use_aggregated  name_tool  \\\n",
       "54   ;image generation;background removal;logo desi...      Kittl   \n",
       "143  ;image editing;image color editing;background ...   PicLumen   \n",
       "152  ;image generation;background removal;image edi...    Recraft   \n",
       "203                                 background removal  Remove.bg   \n",
       "241  ;icon generation;image editing;background remo...     Icons8   \n",
       "\n",
       "       tool_url_y                                   tool_description  \n",
       "54      kittl.com  Kittl is a browser-based design tool offering ...  \n",
       "143  piclumen.com  PicLumen is an AI-driven image creation platfo...  \n",
       "152    recraft.ai  Recraft offers a premium image generation and ...  \n",
       "203     remove.bg  remove.bg automatically removes image backgrou...  \n",
       "241    icons8.com  Icons8 provides apps and tools for design, off...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg_removal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51beecc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3 entries, 250 to 4418\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   tool_id           3 non-null      int64 \n",
      " 1   use_original      0 non-null      object\n",
      " 2   use_aggregated    0 non-null      object\n",
      " 3   name_tool         3 non-null      object\n",
      " 4   tool_url_y        3 non-null      object\n",
      " 5   tool_description  3 non-null      object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 168.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# 4. Filter by keywords in 'tool_description' that are NOT in filtered_df\n",
    "desc_keywords = [\"background removal\"]  # Replace with e.g. [\"software development\", \"gaming\"] as needed\n",
    "\n",
    "# Get all rows in df_selected where 'tool_description' contains any of desc_keywords\n",
    "desc_df_all = filter_by_keywords(df_selected, 'tool_description', desc_keywords)\n",
    "\n",
    "# Exclude those that are already in filtered_df (by tool_id)\n",
    "desc_df = desc_df_all[~desc_df_all['tool_id'].isin(bg_removal['tool_id'])]\n",
    "\n",
    "desc_df.info()\n",
    "\n",
    "# 3. Save to Excel (filename can be parameterized)\n",
    "desc_df.to_excel('background_removal.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3117cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_ids_to_add = [21308, 5342, 18266]  # Example tool_ids\n",
    "# 5. Add missing tool_ids to filtered_df (if needed)\n",
    "\n",
    "bg_removal = add_missing_tool_ids(bg_removal, df_selected, tool_ids_to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93580bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'background_removal': True, 'reason': 'Online editor that instantly removes image backgrounds.'}\n"
     ]
    }
   ],
   "source": [
    "import os, json, openai\n",
    "from pydantic import BaseModel, ValidationError\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")       # keep your key outside code\n",
    "\n",
    "# 1️⃣  Pydantic schema\n",
    "class BGCheck(BaseModel):\n",
    "    background_removal: bool\n",
    "    reason: str | None = None\n",
    "\n",
    "# 2️⃣  Structured‑output request\n",
    "SYSTEM = \"You are a JSON‑only API. Respond via the function call.\"\n",
    "USER_TMPL = \"Does this tool do *background removal*?\\n\\n\\\"\\\"\\\"{desc}\\\"\\\"\\\"\"\n",
    "\n",
    "def check_bg_removal(desc: str) -> BGCheck:\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": USER_TMPL.format(desc=desc)}\n",
    "        ],\n",
    "        functions=[{\n",
    "            \"name\": \"bg_check\",\n",
    "            \"description\": \"Return whether tool performs background removal\",\n",
    "            \"parameters\": BGCheck.model_json_schema()   #  ← auto‑build JSON Schema\n",
    "        }],\n",
    "        function_call={\"name\": \"bg_check\"}              #  ← ask for that output\n",
    "    )\n",
    "\n",
    "    args_json = completion.choices[0].message.function_call.arguments\n",
    "    try:\n",
    "        return BGCheck(**json.loads(args_json))\n",
    "    except (ValidationError, json.JSONDecodeError) as e:\n",
    "        raise RuntimeError(f\"Invalid LLM output: {e}\")\n",
    "\n",
    "# --- quick demo ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    sample = \"Online editor that instantly removes image backgrounds.\"\n",
    "    result = check_bg_removal(sample)\n",
    "    print(result.model_dump())        # {'background_removal': True, 'reason': None}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e37144a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tool_id                                       use_original  \\\n",
      "0    13666  ;image generation;background removal;logo desi...   \n",
      "1    18802  ;image resizing;image color editing;background...   \n",
      "2     5684  ;image generation;background removal;image edi...   \n",
      "3    13467                                ;background removal   \n",
      "4    12663  ;icon generation;image resizing;background rem...   \n",
      "\n",
      "                                      use_aggregated  name_tool    tool_url_y  \\\n",
      "0  ;image generation;background removal;logo desi...      Kittl     kittl.com   \n",
      "1  ;image editing;image color editing;background ...   PicLumen  piclumen.com   \n",
      "2  ;image generation;background removal;image edi...    Recraft    recraft.ai   \n",
      "3                                 background removal  Remove.bg     remove.bg   \n",
      "4  ;icon generation;image editing;background remo...     Icons8    icons8.com   \n",
      "\n",
      "                                    tool_description  background_removal  \\\n",
      "0  Kittl is a browser-based design tool offering ...               False   \n",
      "1  PicLumen is an AI-driven image creation platfo...               False   \n",
      "2  Recraft offers a premium image generation and ...               False   \n",
      "3  remove.bg automatically removes image backgrou...                True   \n",
      "4  Icons8 provides apps and tools for design, off...               False   \n",
      "\n",
      "                                              reason  \n",
      "0  The description does not mention background re...  \n",
      "1  The description does not mention background re...  \n",
      "2  The description does not mention background re...  \n",
      "3  The description indicates that remove.bg autom...  \n",
      "4  The description does not mention background re...  \n"
     ]
    }
   ],
   "source": [
    "# ⬇️ assumes you already executed the earlier cell that defines `check_bg_removal`\n",
    "import pandas as pd\n",
    "\n",
    "# df is the DataFrame you showed:\n",
    "# Columns: tool_id, use_original, use_aggregated, name_tool, tool_url_y, tool_description\n",
    "\n",
    "# 1. Call the LLM once per row and get a dict back\n",
    "results = (\n",
    "    bg_removal[\"tool_description\"]\n",
    "    .apply(lambda desc: check_bg_removal(desc).model_dump())  # → {\"background_removal\":…, \"reason\": …}\n",
    ")\n",
    "\n",
    "# 2. Expand that dict into two columns and attach them in one line\n",
    "bg_removal[[\"background_removal\", \"reason\"]] = results.apply(pd.Series)\n",
    "\n",
    "# Optional: inspect\n",
    "print(bg_removal.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55c9f697",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_USE = \"background removal\"\n",
    "\n",
    "def _to_list(cell: str) -> list[str]:\n",
    "    \"\"\"Convert a ;‑separated string (or NaN) → list without blanks.\"\"\"\n",
    "    if pd.isna(cell):\n",
    "        return []\n",
    "    return [u.strip() for u in str(cell).split(\";\") if u.strip()]\n",
    "\n",
    "def update_use_aggregated(row):\n",
    "    uses = _to_list(row[\"use_aggregated\"])\n",
    "\n",
    "    if row[\"background_removal\"]:\n",
    "        if TARGET_USE not in uses:\n",
    "            uses.append(TARGET_USE)\n",
    "    else:\n",
    "        uses = [u for u in uses if u != TARGET_USE]\n",
    "\n",
    "    # Keep the original style: leading ';' if the cell started with one\n",
    "    prefix = \";\" if str(row[\"use_aggregated\"]).startswith(\";\") else \"\"\n",
    "    return prefix + \";\".join(uses)\n",
    "\n",
    "bg_removal[\"use_aggregated\"] = bg_removal.apply(update_use_aggregated, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "57e61fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_SYSTEM = (\n",
    "    \"You are an analyst with access to a web_search tool. \"\n",
    "    \"Search only enough to decide whether the given tool really performs \"\n",
    "    \"background removal. Return a JSON dict with keys:\\n\"\n",
    "    \"  supports  – bool\\n\"\n",
    "    \"  evidence  – one‑sentence citation‑ready summary\"\n",
    ")\n",
    "\n",
    "def verify_with_web(tool_name: str, tool_url: str) -> tuple[bool, str]:\n",
    "    \"\"\"Ask the search‑preview model for confirmation/evidence.\"\"\"\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini-search-preview\",\n",
    "        temperature=0,\n",
    "        tools=[{\"type\": \"web_search\"}],   # built‑in tool\n",
    "        #tool_choice=\"auto\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SEARCH_SYSTEM},\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": (\n",
    "                 f\"Tool name: {tool_name}\\n\"\n",
    "                 f\"Homepage: {tool_url}\\n\\n\"\n",
    "                 \"Decide if it offers *image background removal*. \"\n",
    "                 \"Use web_search if needed. \"\n",
    "                 \"Respond with JSON {{\\\"supports\\\": <bool>, \\\"evidence\\\": \\\"...\\\"}}.\"\n",
    "             )\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    resp = completion.choices[0].message.content\n",
    "    data = json.loads(resp)\n",
    "    return bool(data[\"supports\"]), str(data[\"evidence\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a3d2016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_bg_check(row) -> BGCheck:\n",
    "    \"\"\"Run the 1st‑pass LLM; if it says False, verify with search.\"\"\"\n",
    "    first = check_bg_removal(row[\"tool_description\"])\n",
    "\n",
    "    if first.background_removal:\n",
    "        return first            # already positive ⇒ trust it\n",
    "\n",
    "    # First pass said “False” – verify\n",
    "    supports, evidence = verify_with_web(row[\"name_tool\"], row[\"tool_url_y\"])\n",
    "\n",
    "    if supports:\n",
    "        return BGCheck(\n",
    "            background_removal=True,\n",
    "            reason=evidence,     # web evidence\n",
    "            verified=True\n",
    "        )\n",
    "    else:\n",
    "        # keep original “False” but mark that we actually checked\n",
    "        first.verified = True\n",
    "        first.reason = (first.reason or \"\") + \" (double‑checked on the web)\"\n",
    "        return first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5504dfaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Missing required parameter: 'tools[0].function'.\", 'type': 'invalid_request_error', 'param': 'tools[0].function', 'code': 'missing_required_parameter'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lz/910twyk903nb6sxfgz54bngc0000gn/T/ipykernel_50777/4228169828.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m results = (\n\u001b[1;32m      3\u001b[0m     \u001b[0mbg_removal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrobust_bg_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# → dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m  10032\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10033\u001b[0m         )\n\u001b[0;32m> 10034\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10036\u001b[0m     def map(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/lz/910twyk903nb6sxfgz54bngc0000gn/T/ipykernel_50777/3858176115.py\u001b[0m in \u001b[0;36mrobust_bg_check\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# First pass said “False” – verify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0msupports\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverify_with_web\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_tool\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tool_url_y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msupports\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/lz/910twyk903nb6sxfgz54bngc0000gn/T/ipykernel_50777/1050627220.py\u001b[0m in \u001b[0;36mverify_with_web\u001b[0;34m(tool_name, tool_url)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mverify_with_web\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_url\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m\"\"\"Ask the search‑preview model for confirmation/evidence.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     completion = openai.chat.completions.create(\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o-mini-search-preview\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariants\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m                     \u001b[0;31m# TODO: this error message is not deterministic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                     \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgiven_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m     def delete(\n\u001b[0m\u001b[1;32m   1284\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m         \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mretries_taken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_retries\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m             \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1 retry left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%i retries left\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Missing required parameter: 'tools[0].function'.\", 'type': 'invalid_request_error', 'param': 'tools[0].function', 'code': 'missing_required_parameter'}}"
     ]
    }
   ],
   "source": [
    "# Call once per row, just like before\n",
    "results = (\n",
    "    bg_removal\n",
    "    .apply(robust_bg_check, axis=1)\n",
    "    .apply(lambda r: r.model_dump())        # → dict\n",
    ")\n",
    "\n",
    "bg_removal[[\"background_removal\", \"reason\", \"verified\"]] = results.apply(pd.Series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36da5a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_removal.to_excel(\"bg_removal.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "094218d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tool_id</th>\n",
       "      <th>use_original</th>\n",
       "      <th>use_aggregated</th>\n",
       "      <th>name_tool</th>\n",
       "      <th>tool_url_y</th>\n",
       "      <th>tool_description</th>\n",
       "      <th>background_removal</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13666</td>\n",
       "      <td>;image generation;background removal;logo desi...</td>\n",
       "      <td>;image generation;logo design;text writing;ima...</td>\n",
       "      <td>Kittl</td>\n",
       "      <td>kittl.com</td>\n",
       "      <td>Kittl is a browser-based design tool offering ...</td>\n",
       "      <td>False</td>\n",
       "      <td>The description does not mention background re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18802</td>\n",
       "      <td>;image resizing;image color editing;background...</td>\n",
       "      <td>;image editing;image color editing;character d...</td>\n",
       "      <td>PicLumen</td>\n",
       "      <td>piclumen.com</td>\n",
       "      <td>PicLumen is an AI-driven image creation platfo...</td>\n",
       "      <td>False</td>\n",
       "      <td>The description does not mention background re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5684</td>\n",
       "      <td>;image generation;background removal;image edi...</td>\n",
       "      <td>;image generation;image editing;mockup generation</td>\n",
       "      <td>Recraft</td>\n",
       "      <td>recraft.ai</td>\n",
       "      <td>Recraft offers a premium image generation and ...</td>\n",
       "      <td>False</td>\n",
       "      <td>The description does not mention background re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13467</td>\n",
       "      <td>;background removal</td>\n",
       "      <td>background removal</td>\n",
       "      <td>Remove.bg</td>\n",
       "      <td>remove.bg</td>\n",
       "      <td>remove.bg automatically removes image backgrou...</td>\n",
       "      <td>True</td>\n",
       "      <td>The description indicates that remove.bg autom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12663</td>\n",
       "      <td>;icon generation;image resizing;background rem...</td>\n",
       "      <td>;icon generation;image editing;face swap;profi...</td>\n",
       "      <td>Icons8</td>\n",
       "      <td>icons8.com</td>\n",
       "      <td>Icons8 provides apps and tools for design, off...</td>\n",
       "      <td>False</td>\n",
       "      <td>The description does not mention background re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tool_id                                       use_original  \\\n",
       "0    13666  ;image generation;background removal;logo desi...   \n",
       "1    18802  ;image resizing;image color editing;background...   \n",
       "2     5684  ;image generation;background removal;image edi...   \n",
       "3    13467                                ;background removal   \n",
       "4    12663  ;icon generation;image resizing;background rem...   \n",
       "\n",
       "                                      use_aggregated  name_tool    tool_url_y  \\\n",
       "0  ;image generation;logo design;text writing;ima...      Kittl     kittl.com   \n",
       "1  ;image editing;image color editing;character d...   PicLumen  piclumen.com   \n",
       "2  ;image generation;image editing;mockup generation    Recraft    recraft.ai   \n",
       "3                                 background removal  Remove.bg     remove.bg   \n",
       "4  ;icon generation;image editing;face swap;profi...     Icons8    icons8.com   \n",
       "\n",
       "                                    tool_description  background_removal  \\\n",
       "0  Kittl is a browser-based design tool offering ...               False   \n",
       "1  PicLumen is an AI-driven image creation platfo...               False   \n",
       "2  Recraft offers a premium image generation and ...               False   \n",
       "3  remove.bg automatically removes image backgrou...                True   \n",
       "4  Icons8 provides apps and tools for design, off...               False   \n",
       "\n",
       "                                              reason  \n",
       "0  The description does not mention background re...  \n",
       "1  The description does not mention background re...  \n",
       "2  The description does not mention background re...  \n",
       "3  The description indicates that remove.bg autom...  \n",
       "4  The description does not mention background re...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg_removal.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f02747",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Background Removal "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633dc660",
   "metadata": {},
   "source": [
    "## Validating autonomous vehicles & transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a04c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your keywords and tool_ids for any use case\n",
    "keywords = [\n",
    "    \"autonomous vehicles & transport\"\n",
    "    # Add more as needed, e.g. \"gaming\", \"software development\", etc.\n",
    "]\n",
    "#tool_ids_to_edit = [3340, 13388, 3703, 11555, 14017, 5056]  # Example tool_ids\n",
    "\n",
    "# 1. Filter by keywords in 'use_original'\n",
    "auto_vehicles = filter_by_keywords(df_selected, 'use_aggregated', keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6cbce33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20 entries, 125 to 18558\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   tool_id           20 non-null     int64 \n",
      " 1   use_original      20 non-null     object\n",
      " 2   use_aggregated    20 non-null     object\n",
      " 3   name_tool         20 non-null     object\n",
      " 4   tool_url_y        20 non-null     object\n",
      " 5   tool_description  20 non-null     object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 1.1+ KB\n"
     ]
    }
   ],
   "source": [
    "auto_vehicles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f4c12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Filter by keywords in 'tool_description' that are NOT in filtered_df\n",
    "desc_keywords = [\"background removal\"]  # Replace with e.g. [\"software development\", \"gaming\"] as needed\n",
    "\n",
    "# Get all rows in df_selected where 'tool_description' contains any of desc_keywords\n",
    "desc_df_all = filter_by_keywords(df_selected, 'tool_description', desc_keywords)\n",
    "\n",
    "# Exclude those that are already in filtered_df (by tool_id)\n",
    "desc_df = desc_df_all[~desc_df_all['tool_id'].isin(bg_removal['tool_id'])]\n",
    "\n",
    "desc_df.info()\n",
    "\n",
    "# 3. Save to Excel (filename can be parameterized)\n",
    "desc_df.to_excel('background_removal.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f9d5f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'autonomous_vehicle_transport': True, 'reason': 'Shield AI develops autonomous systems for drones and aircraft, which are closely related to autonomous vehicle and transport technologies.'}\n"
     ]
    }
   ],
   "source": [
    "import os, json, openai\n",
    "from pydantic import BaseModel, ValidationError\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")       # keep your key outside code\n",
    "\n",
    "# 1️⃣  Pydantic schema\n",
    "class BGCheck(BaseModel):\n",
    "    autonomous_vehicle_transport: bool\n",
    "    reason: str | None = None\n",
    "\n",
    "# 2️⃣  Structured‑output request\n",
    "SYSTEM = \"You are a JSON‑only API. Respond via the function call.\"\n",
    "USER_TMPL = \"Does this tool or company do *autonomous vehicle & transport*, or is very closely related to this use case or business?\\n\\n\\\"\\\"\\\"{desc}\\\"\\\"\\\"\"\n",
    "\n",
    "def check_desc(desc: str) -> BGCheck:\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": USER_TMPL.format(desc=desc)}\n",
    "        ],\n",
    "        functions=[{\n",
    "            \"name\": \"autonomous\",\n",
    "            \"description\": \"Return whether tool performs autonomous vehicle & transport\",\n",
    "            \"parameters\": BGCheck.model_json_schema()   #  ← auto‑build JSON Schema\n",
    "        }],\n",
    "        function_call={\"name\": \"autonomous\"}              #  ← ask for that output\n",
    "    )\n",
    "\n",
    "    args_json = completion.choices[0].message.function_call.arguments\n",
    "    try:\n",
    "        return BGCheck(**json.loads(args_json))\n",
    "    except (ValidationError, json.JSONDecodeError) as e:\n",
    "        raise RuntimeError(f\"Invalid LLM output: {e}\")\n",
    "\n",
    "# --- quick demo ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    sample = \"Shield AI builds autonomous systems for drones and aircraft, focusing on the Hivemind AI pilot to enable operations without GPS or human pilots, providing innovative solutions for both military and commercial use.\"\n",
    "    result = check_desc(sample)\n",
    "    print(result.model_dump())        # {'background_removal': True, 'reason': None}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1645af99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tool_id                                     use_original  \\\n",
      "125     12158                 ;autonomous vehicles & transport   \n",
      "126     12140                 ;autonomous vehicles & transport   \n",
      "136     12153                 ;autonomous vehicles & transport   \n",
      "537      6721                                  ;model training   \n",
      "1032    13067  ;predictive analytics;sensor fusion;ai copilots   \n",
      "\n",
      "                                         use_aggregated  name_tool tool_url_y  \\\n",
      "125                     autonomous vehicles & transport    Pony.ai    pony.ai   \n",
      "126                     autonomous vehicles & transport  Shield AI  shield.ai   \n",
      "136                     autonomous vehicles & transport       Nuro    nuro.ai   \n",
      "537      model training;autonomous vehicles & transport     PlusAI    plus.ai   \n",
      "1032  predictive analytics;sensor fusion;ai copilots...    Helm.ai    helm.ai   \n",
      "\n",
      "                                       tool_description  \\\n",
      "125   Pony.ai is a global leader in autonomous drivi...   \n",
      "126   Shield AI builds autonomous systems for drones...   \n",
      "136   Nuro offers AI-first autonomous driving techno...   \n",
      "537   Plus revolutionizes autonomous driving with a ...   \n",
      "1032  Helm.ai provides AI solutions for ADAS to L4 a...   \n",
      "\n",
      "      autonomous_vehicle_transport  \\\n",
      "125                           True   \n",
      "126                           True   \n",
      "136                           True   \n",
      "537                           True   \n",
      "1032                          True   \n",
      "\n",
      "                                                 reason  \n",
      "125   Pony.ai specializes in autonomous driving tech...  \n",
      "126   Shield AI develops autonomous systems for dron...  \n",
      "136   Nuro specializes in AI-first autonomous drivin...  \n",
      "537   The company focuses on autonomous driving and ...  \n",
      "1032  Helm.ai provides AI solutions specifically for...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lz/910twyk903nb6sxfgz54bngc0000gn/T/ipykernel_50777/1554959920.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auto_vehicles[[\"autonomous_vehicle_transport\", \"reason\"]] = results.apply(pd.Series)\n"
     ]
    }
   ],
   "source": [
    "# ⬇️ assumes you already executed the earlier cell that defines `check_bg_removal`\n",
    "import pandas as pd\n",
    "\n",
    "# df is the DataFrame you showed:\n",
    "# Columns: tool_id, use_original, use_aggregated, name_tool, tool_url_y, tool_description\n",
    "\n",
    "# 1. Call the LLM once per row and get a dict back\n",
    "results = (\n",
    "    auto_vehicles[\"tool_description\"]\n",
    "    .apply(lambda desc: check_desc(desc).model_dump())  # → {\"background_removal\":…, \"reason\": …}\n",
    ")\n",
    "\n",
    "# 2. Expand that dict into two columns and attach them in one line\n",
    "auto_vehicles[[\"autonomous_vehicle_transport\", \"reason\"]] = results.apply(pd.Series)\n",
    "\n",
    "# Optional: inspect\n",
    "print(auto_vehicles.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7666555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tool_id</th>\n",
       "      <th>use_original</th>\n",
       "      <th>use_aggregated</th>\n",
       "      <th>name_tool</th>\n",
       "      <th>tool_url_y</th>\n",
       "      <th>tool_description</th>\n",
       "      <th>autonomous_vehicle_transport</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>12158</td>\n",
       "      <td>;autonomous vehicles &amp; transport</td>\n",
       "      <td>autonomous vehicles &amp; transport</td>\n",
       "      <td>Pony.ai</td>\n",
       "      <td>pony.ai</td>\n",
       "      <td>Pony.ai is a global leader in autonomous drivi...</td>\n",
       "      <td>True</td>\n",
       "      <td>Pony.ai specializes in autonomous driving tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>12140</td>\n",
       "      <td>;autonomous vehicles &amp; transport</td>\n",
       "      <td>autonomous vehicles &amp; transport</td>\n",
       "      <td>Shield AI</td>\n",
       "      <td>shield.ai</td>\n",
       "      <td>Shield AI builds autonomous systems for drones...</td>\n",
       "      <td>True</td>\n",
       "      <td>Shield AI develops autonomous systems for dron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>12153</td>\n",
       "      <td>;autonomous vehicles &amp; transport</td>\n",
       "      <td>autonomous vehicles &amp; transport</td>\n",
       "      <td>Nuro</td>\n",
       "      <td>nuro.ai</td>\n",
       "      <td>Nuro offers AI-first autonomous driving techno...</td>\n",
       "      <td>True</td>\n",
       "      <td>Nuro specializes in AI-first autonomous drivin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>6721</td>\n",
       "      <td>;model training</td>\n",
       "      <td>model training;autonomous vehicles &amp; transport</td>\n",
       "      <td>PlusAI</td>\n",
       "      <td>plus.ai</td>\n",
       "      <td>Plus revolutionizes autonomous driving with a ...</td>\n",
       "      <td>True</td>\n",
       "      <td>The company focuses on autonomous driving and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>13067</td>\n",
       "      <td>;predictive analytics;sensor fusion;ai copilots</td>\n",
       "      <td>predictive analytics;sensor fusion;ai copilots...</td>\n",
       "      <td>Helm.ai</td>\n",
       "      <td>helm.ai</td>\n",
       "      <td>Helm.ai provides AI solutions for ADAS to L4 a...</td>\n",
       "      <td>True</td>\n",
       "      <td>Helm.ai provides AI solutions specifically for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tool_id                                     use_original  \\\n",
       "125     12158                 ;autonomous vehicles & transport   \n",
       "126     12140                 ;autonomous vehicles & transport   \n",
       "136     12153                 ;autonomous vehicles & transport   \n",
       "537      6721                                  ;model training   \n",
       "1032    13067  ;predictive analytics;sensor fusion;ai copilots   \n",
       "\n",
       "                                         use_aggregated  name_tool tool_url_y  \\\n",
       "125                     autonomous vehicles & transport    Pony.ai    pony.ai   \n",
       "126                     autonomous vehicles & transport  Shield AI  shield.ai   \n",
       "136                     autonomous vehicles & transport       Nuro    nuro.ai   \n",
       "537      model training;autonomous vehicles & transport     PlusAI    plus.ai   \n",
       "1032  predictive analytics;sensor fusion;ai copilots...    Helm.ai    helm.ai   \n",
       "\n",
       "                                       tool_description  \\\n",
       "125   Pony.ai is a global leader in autonomous drivi...   \n",
       "126   Shield AI builds autonomous systems for drones...   \n",
       "136   Nuro offers AI-first autonomous driving techno...   \n",
       "537   Plus revolutionizes autonomous driving with a ...   \n",
       "1032  Helm.ai provides AI solutions for ADAS to L4 a...   \n",
       "\n",
       "      autonomous_vehicle_transport  \\\n",
       "125                           True   \n",
       "126                           True   \n",
       "136                           True   \n",
       "537                           True   \n",
       "1032                          True   \n",
       "\n",
       "                                                 reason  \n",
       "125   Pony.ai specializes in autonomous driving tech...  \n",
       "126   Shield AI develops autonomous systems for dron...  \n",
       "136   Nuro specializes in AI-first autonomous drivin...  \n",
       "537   The company focuses on autonomous driving and ...  \n",
       "1032  Helm.ai provides AI solutions specifically for...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_vehicles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9393469",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_USE = \"background removal\"\n",
    "\n",
    "def _to_list(cell: str) -> list[str]:\n",
    "    \"\"\"Convert a ;‑separated string (or NaN) → list without blanks.\"\"\"\n",
    "    if pd.isna(cell):\n",
    "        return []\n",
    "    return [u.strip() for u in str(cell).split(\";\") if u.strip()]\n",
    "\n",
    "def update_use_aggregated(row):\n",
    "    uses = _to_list(row[\"use_aggregated\"])\n",
    "\n",
    "    if row[\"background_removal\"]:\n",
    "        if TARGET_USE not in uses:\n",
    "            uses.append(TARGET_USE)\n",
    "    else:\n",
    "        uses = [u for u in uses if u != TARGET_USE]\n",
    "\n",
    "    # Keep the original style: leading ';' if the cell started with one\n",
    "    prefix = \";\" if str(row[\"use_aggregated\"]).startswith(\";\") else \"\"\n",
    "    return prefix + \";\".join(uses)\n",
    "\n",
    "bg_removal[\"use_aggregated\"] = bg_removal.apply(update_use_aggregated, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ddc4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_removal.to_excel(\"bg_removal.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086fa45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BGCheck(BaseModel):\n",
    "    background_removal: bool\n",
    "    reason: str | None = None\n",
    "    verified: bool = False          # ← True = second‑pass verification ran\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00f5087",
   "metadata": {},
   "source": [
    "## Validating legal assictance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad18c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your keywords and tool_ids for any use case\n",
    "keywords = [\n",
    "    \"legal assistance\"\n",
    "    # Add more as needed, e.g. \"gaming\", \"software development\", etc.\n",
    "]\n",
    "#tool_ids_to_edit = [3340, 13388, 3703, 11555, 14017, 5056]  # Example tool_ids\n",
    "\n",
    "# 1. Filter by keywords in 'use_original'\n",
    "legal_assistance = filter_by_keywords(df_selected, 'use_aggregated', keywords)\n",
    "\n",
    "# 2. Save to Excel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15cb907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25 entries, 158 to 18977\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   tool_id           25 non-null     int64 \n",
      " 1   use_original      24 non-null     object\n",
      " 2   use_aggregated    25 non-null     object\n",
      " 3   name_tool         25 non-null     object\n",
      " 4   tool_url_y        25 non-null     object\n",
      " 5   tool_description  24 non-null     object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 1.4+ KB\n"
     ]
    }
   ],
   "source": [
    "legal_assistance.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e75504fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4 entries, 11360 to 15440\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   tool_id           4 non-null      int64 \n",
      " 1   use_original      4 non-null      object\n",
      " 2   use_aggregated    4 non-null      object\n",
      " 3   name_tool         4 non-null      object\n",
      " 4   tool_url_y        4 non-null      object\n",
      " 5   tool_description  4 non-null      object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 224.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# 4. Filter by keywords in 'tool_description' that are NOT in filtered_df\n",
    "desc_keywords = [\"legal assistance\"]  # Replace with e.g. [\"software development\", \"gaming\"] as needed\n",
    "\n",
    "# Get all rows in df_selected where 'tool_description' contains any of desc_keywords\n",
    "desc_df_all = filter_by_keywords(df_selected, 'tool_description', desc_keywords)\n",
    "\n",
    "# Exclude those that are already in filtered_df (by tool_id)\n",
    "desc_df = desc_df_all[~desc_df_all['tool_id'].isin(legal_assistance['tool_id'])]\n",
    "\n",
    "desc_df.info()\n",
    "\n",
    "# 3. Save to Excel (filename can be parameterized)\n",
    "desc_df.to_excel('legal_assistance2.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75100e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'legal_assistance': True, 'reason': 'The platform provides access to various legal services, including contesting parking tickets, which qualifies as legal assistance.'}\n"
     ]
    }
   ],
   "source": [
    "import os, json, openai\n",
    "from pydantic import BaseModel, ValidationError\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")       # keep your key outside code\n",
    "\n",
    "# 1️⃣  Pydantic schema\n",
    "class BGCheck(BaseModel):\n",
    "    legal_assistance: bool\n",
    "    reason: str | None = None\n",
    "\n",
    "# 2️⃣  Structured‑output request\n",
    "SYSTEM = \"You are a JSON‑only API. Respond via the function call.\"\n",
    "USER_TMPL = \"Does this tool or company do *legal assistance*, or is very closely related to this use case or business?\\n\\n\\\"\\\"\\\"{desc}\\\"\\\"\\\"\"\n",
    "\n",
    "def check_desc(desc: str) -> BGCheck:\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": USER_TMPL.format(desc=desc)}\n",
    "        ],\n",
    "        functions=[{\n",
    "            \"name\": \"legal_assistance\",\n",
    "            \"description\": \"Return whether tool performs legal assistance\",\n",
    "            \"parameters\": BGCheck.model_json_schema()   #  ← auto‑build JSON Schema\n",
    "        }],\n",
    "        function_call={\"name\": \"legal_assistance\"}              #  ← ask for that output\n",
    "    )\n",
    "\n",
    "    args_json = completion.choices[0].message.function_call.arguments\n",
    "    try:\n",
    "        return BGCheck(**json.loads(args_json))\n",
    "    except (ValidationError, json.JSONDecodeError) as e:\n",
    "        raise RuntimeError(f\"Invalid LLM output: {e}\")\n",
    "\n",
    "# --- quick demo ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    sample = \"DoNotPay is an AI-powered platform that helps users contest parking tickets, manage subscriptions, and access various legal services, making legal assistance more accessible and affordable.\"\n",
    "    result = check_desc(sample)\n",
    "    print(result.model_dump())        # {'legal_assistance': True, 'reason': ...}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "545d9452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tool_id                                       use_original  \\\n",
      "158     13774  ;(academic) literature review;document analysi...   \n",
      "632       895                  ;legal assistance;data management   \n",
      "1211    13144  ;legal assistance;email automation;invoice & p...   \n",
      "1449     3962  ;document processing;contract review & analysi...   \n",
      "1986    12957                                  ;legal assistance   \n",
      "\n",
      "                                         use_aggregated          name_tool  \\\n",
      "158   ;(academic) literature review;document analysi...             Harvey   \n",
      "632                   ;legal assistance;data management  Reveal-Brainspace   \n",
      "1211  ;legal assistance;email marketing & automation...            Tonkean   \n",
      "1449  ;document processing;contract review & analysi...          Spellbook   \n",
      "1986                                  ;legal assistance  Onna Technologies   \n",
      "\n",
      "           tool_url_y                                   tool_description  \\\n",
      "158         harvey.ai  Harvey provides a secure and integrated platfo...   \n",
      "632    revealdata.com  Reveal delivers AI-driven eDiscovery solutions...   \n",
      "1211      tonkean.com  Tonkean provides AI-powered enterprise intake ...   \n",
      "1449  spellbook.legal  Spellbook enhances legal workflows by streamli...   \n",
      "1986         onna.com  Onna centralizes and secures unstructured ente...   \n",
      "\n",
      "      legal_assistance                                             reason  \n",
      "158               True  Harvey's platform is designed specifically for...  \n",
      "632               True  The company provides eDiscovery solutions for ...  \n",
      "1211              True  Tonkean operates in the legal domain and provi...  \n",
      "1449              True  Spellbook enhances legal workflows, which incl...  \n",
      "1986             False  Onna focuses on data management and integratio...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lz/910twyk903nb6sxfgz54bngc0000gn/T/ipykernel_28883/3022791949.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  legal_assistance[[\"legal_assistance\", \"reason\"]] = results.apply(pd.Series)\n",
      "/var/folders/lz/910twyk903nb6sxfgz54bngc0000gn/T/ipykernel_28883/3022791949.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  legal_assistance[[\"legal_assistance\", \"reason\"]] = results.apply(pd.Series)\n"
     ]
    }
   ],
   "source": [
    "# ⬇️ assumes you already executed the earlier cell that defines `check_bg_removal`\n",
    "import pandas as pd\n",
    "\n",
    "# df is the DataFrame you showed:\n",
    "# Columns: tool_id, use_original, use_aggregated, name_tool, tool_url_y, tool_description\n",
    "\n",
    "# 1. Call the LLM once per row and get a dict back\n",
    "results = (\n",
    "    legal_assistance[\"tool_description\"]\n",
    "    .apply(lambda desc: check_desc(desc).model_dump())  # → {\"background_removal\":…, \"reason\": …}\n",
    ")\n",
    "\n",
    "# 2. Expand that dict into two columns and attach them in one line\n",
    "legal_assistance[[\"legal_assistance\", \"reason\"]] = results.apply(pd.Series)\n",
    "\n",
    "# Optional: inspect\n",
    "print(legal_assistance.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053b89c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_assistance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd2f5499",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lz/910twyk903nb6sxfgz54bngc0000gn/T/ipykernel_28883/2136605413.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  legal_assistance[\"use_aggregated\"] = legal_assistance.apply(update_use_aggregated, axis=1)\n"
     ]
    }
   ],
   "source": [
    "TARGET_USE = \"legal assistance\"\n",
    "\n",
    "def _to_list(cell: str) -> list[str]:\n",
    "    \"\"\"Convert a ;‑separated string (or NaN) → list without blanks.\"\"\"\n",
    "    if pd.isna(cell):\n",
    "        return []\n",
    "    return [u.strip() for u in str(cell).split(\";\") if u.strip()]\n",
    "\n",
    "def update_use_aggregated(row):\n",
    "    uses = _to_list(row[\"use_aggregated\"])\n",
    "\n",
    "    if row[\"legal_assistance\"]:\n",
    "        if TARGET_USE not in uses:\n",
    "            uses.append(TARGET_USE)\n",
    "    else:\n",
    "        uses = [u for u in uses if u != TARGET_USE]\n",
    "\n",
    "    # Keep the original style: leading ';' if the cell started with one\n",
    "    prefix = \";\" if str(row[\"use_aggregated\"]).startswith(\";\") else \"\"\n",
    "    return prefix + \";\".join(uses)\n",
    "\n",
    "legal_assistance[\"use_aggregated\"] = legal_assistance.apply(update_use_aggregated, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69692684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the legal_assistance DataFrame to an Excel file\n",
    "legal_assistance.to_excel(\"legal_assistance.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b653c4",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994b1325",
   "metadata": {},
   "source": [
    "## Validating audio generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f2e703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your keywords and tool_ids for any use case\n",
    "keywords = [\n",
    "    \"audio generation\"\n",
    "    # Add more as needed, e.g. \"gaming\", \"software development\", etc.\n",
    "]\n",
    "#tool_ids_to_edit = [3340, 13388, 3703, 11555, 14017, 5056]  # Example tool_ids\n",
    "\n",
    "# 1. Filter by keywords in 'use_original'\n",
    "audio = filter_by_keywords(df_selected, 'use_aggregated', keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "145fe4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4 entries, 2479 to 12335\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   tool_id           4 non-null      int64 \n",
      " 1   use_original      4 non-null      object\n",
      " 2   use_aggregated    4 non-null      object\n",
      " 3   name_tool         4 non-null      object\n",
      " 4   tool_url_y        4 non-null      object\n",
      " 5   tool_description  4 non-null      object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 224.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# 4. Filter by keywords in 'tool_description' that are NOT in filtered_df\n",
    "desc_keywords = [\"audio generation\"]  # Replace with e.g. [\"software development\", \"gaming\"] as needed\n",
    "\n",
    "# Get all rows in df_selected where 'tool_description' contains any of desc_keywords\n",
    "desc_df_all = filter_by_keywords(df_selected, 'tool_description', desc_keywords)\n",
    "\n",
    "# Exclude those that are already in filtered_df (by tool_id)\n",
    "desc_df = desc_df_all[~desc_df_all['tool_id'].isin(audio['tool_id'])]\n",
    "\n",
    "desc_df.info()\n",
    "\n",
    "# 3. Save to Excel (filename can be parameterized)\n",
    "desc_df.to_excel('audio_generation.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ccce359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': False, 'reason': 'The company focuses on autonomous systems for drones and aircraft, which does not involve audio generation.'}\n"
     ]
    }
   ],
   "source": [
    "import os, json, openai\n",
    "from pydantic import BaseModel, ValidationError\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")       # keep your key outside code\n",
    "\n",
    "# 1️⃣  Pydantic schema\n",
    "class BGCheck(BaseModel):\n",
    "    audio: bool\n",
    "    reason: str | None = None\n",
    "\n",
    "# 2️⃣  Structured‑output request\n",
    "SYSTEM = \"You are a JSON‑only API. Respond via the function call.\"\n",
    "USER_TMPL = \"Does this tool or company do *audio generation*, or is very closely related to this use case or business?\\n\\n\\\"\\\"\\\"{desc}\\\"\\\"\\\"\"\n",
    "\n",
    "def check_desc(desc: str) -> BGCheck:\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": USER_TMPL.format(desc=desc)}\n",
    "        ],\n",
    "        functions=[{\n",
    "            \"name\": \"audio\",\n",
    "            \"description\": \"Return whether tool performs audio generation\",\n",
    "            \"parameters\": BGCheck.model_json_schema()   #  ← auto‑build JSON Schema\n",
    "        }],\n",
    "        function_call={\"name\": \"audio\"}              #  ← ask for that output\n",
    "    )\n",
    "\n",
    "    args_json = completion.choices[0].message.function_call.arguments\n",
    "    try:\n",
    "        return BGCheck(**json.loads(args_json))\n",
    "    except (ValidationError, json.JSONDecodeError) as e:\n",
    "        raise RuntimeError(f\"Invalid LLM output: {e}\")\n",
    "\n",
    "# --- quick demo ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    sample = \"Shield AI builds autonomous systems for drones and aircraft, focusing on the Hivemind AI pilot to enable operations without GPS or human pilots, providing innovative solutions for both military and commercial use.\"\n",
    "    result = check_desc(sample)\n",
    "    print(result.model_dump())        # {'background_removal': True, 'reason': None}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4525c295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tool_id                                       use_original  \\\n",
      "11      6552            ;audio generation;music recommendations   \n",
      "32      6760  ;video editing;avatar generation;audio generat...   \n",
      "591     5842                                  ;audio generation   \n",
      "659     7636      ;audio editing;text to audio;audio generation   \n",
      "671     6080  ;video editing;caption generation;image manage...   \n",
      "\n",
      "                                        use_aggregated       name_tool  \\\n",
      "11             ;audio generation;music recommendations  Epidemic Sound   \n",
      "32   video editing;avatar generation;audio generati...       Synthesia   \n",
      "591                                  ;audio generation     cartesia.ai   \n",
      "659      ;audio editing;text to audio;audio generation         Replica   \n",
      "671  ;video editing;caption generation;image manage...        Submagic   \n",
      "\n",
      "             tool_url_y                                   tool_description  \\\n",
      "11    epidemicsound.com  Epidemic Sound offers a vast catalog of royalt...   \n",
      "32         synthesia.io  Synthesia provides an AI platform for creating...   \n",
      "591         cartesia.ai  Cartesia offers real-time multimodal intellige...   \n",
      "659  replicastudios.com  Replica Studios provides AI-driven voice gener...   \n",
      "671         submagic.co  Submagic offers a streamlined video editing to...   \n",
      "\n",
      "     audio                                             reason  \n",
      "11    True  Epidemic Sound provides royalty-free music and...  \n",
      "32    True  Synthesia's platform includes voiceovers, whic...  \n",
      "591   True  The mention of generative voice APIs indicates...  \n",
      "659   True  Replica Studios provides AI-driven voice gener...  \n",
      "671  False  Submagic focuses on video editing and content ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lz/910twyk903nb6sxfgz54bngc0000gn/T/ipykernel_28883/1075009728.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  audio[[\"audio\", \"reason\"]] = results.apply(pd.Series)\n",
      "/var/folders/lz/910twyk903nb6sxfgz54bngc0000gn/T/ipykernel_28883/1075009728.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  audio[[\"audio\", \"reason\"]] = results.apply(pd.Series)\n"
     ]
    }
   ],
   "source": [
    "# ⬇️ assumes you already executed the earlier cell that defines `check_bg_removal`\n",
    "import pandas as pd\n",
    "\n",
    "# df is the DataFrame you showed:\n",
    "# Columns: tool_id, use_original, use_aggregated, name_tool, tool_url_y, tool_description\n",
    "\n",
    "# 1. Call the LLM once per row and get a dict back\n",
    "results = (\n",
    "    audio[\"tool_description\"]\n",
    "    .apply(lambda desc: check_desc(desc).model_dump())  # → {\"background_removal\":…, \"reason\": …}\n",
    ")\n",
    "\n",
    "# 2. Expand that dict into two columns and attach them in one line\n",
    "audio[[\"audio\", \"reason\"]] = results.apply(pd.Series)\n",
    "\n",
    "# Optional: inspect\n",
    "print(audio.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2354d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lz/910twyk903nb6sxfgz54bngc0000gn/T/ipykernel_28883/4111307947.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  audio[\"use_aggregated\"] = audio.apply(update_use_aggregated, axis=1)\n"
     ]
    }
   ],
   "source": [
    "TARGET_USE = \"audio generation\"\n",
    "\n",
    "def _to_list(cell: str) -> list[str]:\n",
    "    \"\"\"Convert a ;‑separated string (or NaN) → list without blanks.\"\"\"\n",
    "    if pd.isna(cell):\n",
    "        return []\n",
    "    return [u.strip() for u in str(cell).split(\";\") if u.strip()]\n",
    "\n",
    "def update_use_aggregated(row):\n",
    "    uses = _to_list(row[\"use_aggregated\"])\n",
    "\n",
    "    if row[\"audio\"]:\n",
    "        if TARGET_USE not in uses:\n",
    "            uses.append(TARGET_USE)\n",
    "    else:\n",
    "        uses = [u for u in uses if u != TARGET_USE]\n",
    "\n",
    "    # Keep the original style: leading ';' if the cell started with one\n",
    "    prefix = \";\" if str(row[\"use_aggregated\"]).startswith(\";\") else \"\"\n",
    "    return prefix + \";\".join(uses)\n",
    "\n",
    "audio[\"use_aggregated\"] = audio.apply(update_use_aggregated, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c03772d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tool_id</th>\n",
       "      <th>use_original</th>\n",
       "      <th>use_aggregated</th>\n",
       "      <th>name_tool</th>\n",
       "      <th>tool_url_y</th>\n",
       "      <th>tool_description</th>\n",
       "      <th>audio</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6552</td>\n",
       "      <td>;audio generation;music recommendations</td>\n",
       "      <td>;audio generation;music recommendations</td>\n",
       "      <td>Epidemic Sound</td>\n",
       "      <td>epidemicsound.com</td>\n",
       "      <td>Epidemic Sound offers a vast catalog of royalt...</td>\n",
       "      <td>True</td>\n",
       "      <td>Epidemic Sound provides royalty-free music and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6760</td>\n",
       "      <td>;video editing;avatar generation;audio generat...</td>\n",
       "      <td>video editing;avatar generation;audio generati...</td>\n",
       "      <td>Synthesia</td>\n",
       "      <td>synthesia.io</td>\n",
       "      <td>Synthesia provides an AI platform for creating...</td>\n",
       "      <td>True</td>\n",
       "      <td>Synthesia's platform includes voiceovers, whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>5842</td>\n",
       "      <td>;audio generation</td>\n",
       "      <td>;audio generation</td>\n",
       "      <td>cartesia.ai</td>\n",
       "      <td>cartesia.ai</td>\n",
       "      <td>Cartesia offers real-time multimodal intellige...</td>\n",
       "      <td>True</td>\n",
       "      <td>The mention of generative voice APIs indicates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>7636</td>\n",
       "      <td>;audio editing;text to audio;audio generation</td>\n",
       "      <td>;audio editing;text to audio;audio generation</td>\n",
       "      <td>Replica</td>\n",
       "      <td>replicastudios.com</td>\n",
       "      <td>Replica Studios provides AI-driven voice gener...</td>\n",
       "      <td>True</td>\n",
       "      <td>Replica Studios provides AI-driven voice gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>6080</td>\n",
       "      <td>;video editing;caption generation;image manage...</td>\n",
       "      <td>;video editing;caption generation;image manage...</td>\n",
       "      <td>Submagic</td>\n",
       "      <td>submagic.co</td>\n",
       "      <td>Submagic offers a streamlined video editing to...</td>\n",
       "      <td>False</td>\n",
       "      <td>Submagic focuses on video editing and content ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tool_id                                       use_original  \\\n",
       "11      6552            ;audio generation;music recommendations   \n",
       "32      6760  ;video editing;avatar generation;audio generat...   \n",
       "591     5842                                  ;audio generation   \n",
       "659     7636      ;audio editing;text to audio;audio generation   \n",
       "671     6080  ;video editing;caption generation;image manage...   \n",
       "\n",
       "                                        use_aggregated       name_tool  \\\n",
       "11             ;audio generation;music recommendations  Epidemic Sound   \n",
       "32   video editing;avatar generation;audio generati...       Synthesia   \n",
       "591                                  ;audio generation     cartesia.ai   \n",
       "659      ;audio editing;text to audio;audio generation         Replica   \n",
       "671  ;video editing;caption generation;image manage...        Submagic   \n",
       "\n",
       "             tool_url_y                                   tool_description  \\\n",
       "11    epidemicsound.com  Epidemic Sound offers a vast catalog of royalt...   \n",
       "32         synthesia.io  Synthesia provides an AI platform for creating...   \n",
       "591         cartesia.ai  Cartesia offers real-time multimodal intellige...   \n",
       "659  replicastudios.com  Replica Studios provides AI-driven voice gener...   \n",
       "671         submagic.co  Submagic offers a streamlined video editing to...   \n",
       "\n",
       "     audio                                             reason  \n",
       "11    True  Epidemic Sound provides royalty-free music and...  \n",
       "32    True  Synthesia's platform includes voiceovers, whic...  \n",
       "591   True  The mention of generative voice APIs indicates...  \n",
       "659   True  Replica Studios provides AI-driven voice gener...  \n",
       "671  False  Submagic focuses on video editing and content ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "459b510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the `audio` DataFrame to an Excel file\n",
    "audio.to_excel(\"audio_cleaned.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75706c2d",
   "metadata": {},
   "source": [
    "## Validating interviews & interview management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32cdc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 50 entries, 1978 to 18927\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   tool_id           50 non-null     int64 \n",
      " 1   use_original      40 non-null     object\n",
      " 2   use_aggregated    36 non-null     object\n",
      " 3   name_tool         50 non-null     object\n",
      " 4   tool_url_y        50 non-null     object\n",
      " 5   tool_description  50 non-null     object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 2.7+ KB\n",
      "{'relevant': True, 'reason': 'HireVue specializes in digital interviewing and candidate screening, which directly relates to interview management.'}\n",
      "     tool_id                                       use_original  \\\n",
      "58       725  ;market research;competitor analysis;interview...   \n",
      "72     12155  ;recruiting & hiring;crm solutions;conversatio...   \n",
      "244    12659  ;interviews & interview management;learning an...   \n",
      "376    13778           ;interview automation;payroll management   \n",
      "565     5206            ;recruiting & hiring;interview analysis   \n",
      "\n",
      "                                        use_aggregated    name_tool  \\\n",
      "58   market research;competitor analysis;interviews...   AlphaSense   \n",
      "72   recruiting & hiring;crm solutions;conversation...   Paradox ai   \n",
      "244  interviews & interview management;learning and...  HackerEarth   \n",
      "376           ;interview automation;payroll management  Gpt Vetting   \n",
      "565            ;recruiting & hiring;interview analysis         Kula   \n",
      "\n",
      "          tool_url_y                                   tool_description  \\\n",
      "58   alpha-sense.com  AlphaSense offers a generative AI-powered plat...   \n",
      "72        paradox.ai  Paradox provides conversational hiring automat...   \n",
      "244  hackerearth.com  HackerEarth offers a comprehensive platform fo...   \n",
      "376        micro1.ai  Micro1 provides an AI recruitment engine to hi...   \n",
      "565          kula.ai  Kula is an all-in-one ATS platform that integr...   \n",
      "\n",
      "     relevant                                             reason  \n",
      "58      False  AlphaSense focuses on market intelligence and ...  \n",
      "72       True  Paradox's conversational hiring automation too...  \n",
      "244      True  HackerEarth provides a platform that includes ...  \n",
      "376      True  The AI recruitment engine implies involvement ...  \n",
      "565      True  Kula is an ATS platform that streamlines the h...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lz/910twyk903nb6sxfgz54bngc0000gn/T/ipykernel_28883/839994927.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_use[[\"relevant\", \"reason\"]] = results.apply(pd.Series)\n",
      "/var/folders/lz/910twyk903nb6sxfgz54bngc0000gn/T/ipykernel_28883/839994927.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_use[[\"relevant\", \"reason\"]] = results.apply(pd.Series)\n",
      "/var/folders/lz/910twyk903nb6sxfgz54bngc0000gn/T/ipykernel_28883/839994927.py:106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_use[\"use_aggregated\"] = df_use.apply(update_use_aggregated, axis=1)\n"
     ]
    }
   ],
   "source": [
    "# --- Modular pipeline for any use case (example: interviews & interview management) ---\n",
    "\n",
    "import os, json, openai\n",
    "from pydantic import BaseModel, ValidationError\n",
    "import pandas as pd\n",
    "\n",
    "# === 1. CONFIGURATION: Set your use case here ===\n",
    "USE_CASE = \"interviews & interview management\"\n",
    "TARGET_USE = \"interviews & interview management\"\n",
    "KEYWORDS = [\n",
    "    \"interview\",\n",
    "    \"interview management\",\n",
    "    \"candidate screening\",\n",
    "    \"interview scheduling\",\n",
    "    \"interview analytics\",\n",
    "    # Add more as needed\n",
    "]\n",
    "EXCEL_OUT = \"interviews_management_cleaned.xlsx\"\n",
    "\n",
    "# === 2. Filter by keywords in 'use_aggregated' ===\n",
    "def filter_by_keywords(df, col, keywords):\n",
    "    \"\"\"Return rows where any keyword appears in the given column (case-insensitive).\"\"\"\n",
    "    pattern = \"|\".join([rf\"\\b{k}\\b\" for k in keywords])\n",
    "    return df[df[col].str.contains(pattern, case=False, na=False)]\n",
    "\n",
    "# Use your main DataFrame (replace as needed)\n",
    "df_use = filter_by_keywords(df_selected, 'use_aggregated', KEYWORDS)\n",
    "\n",
    "# === 3. Filter by keywords in 'tool_description' not already in df_use ===\n",
    "desc_df_all = filter_by_keywords(df_selected, 'tool_description', KEYWORDS)\n",
    "desc_df = desc_df_all[~desc_df_all['tool_id'].isin(df_use['tool_id'])]\n",
    "\n",
    "# Optional: inspect\n",
    "desc_df.info()\n",
    "\n",
    "# === 4. Save to Excel (filename parameterized) ===\n",
    "desc_df.to_excel(EXCEL_OUT, index=False)\n",
    "\n",
    "# === 5. LLM schema and function for this use case ===\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")       # keep your key outside code\n",
    "\n",
    "class UseCaseCheck(BaseModel):\n",
    "    relevant: bool\n",
    "    reason: str | None = None\n",
    "\n",
    "SYSTEM = \"You are a JSON‑only API. Respond via the function call.\"\n",
    "USER_TMPL = (\n",
    "    f\"Does this tool or company do *{USE_CASE}*, or is very closely related to this use case or business?\\n\\n\"\n",
    "    \"\\\"\\\"\\\"{desc}\\\"\\\"\\\"\"\n",
    ")\n",
    "\n",
    "def check_desc(desc: str) -> UseCaseCheck:\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": USER_TMPL.format(desc=desc)}\n",
    "        ],\n",
    "        functions=[{\n",
    "            \"name\": \"relevant\",\n",
    "            \"description\": f\"Return whether tool performs {USE_CASE}\",\n",
    "            \"parameters\": UseCaseCheck.model_json_schema()\n",
    "        }],\n",
    "        function_call={\"name\": \"relevant\"}\n",
    "    )\n",
    "    args_json = completion.choices[0].message.function_call.arguments\n",
    "    try:\n",
    "        return UseCaseCheck(**json.loads(args_json))\n",
    "    except (ValidationError, json.JSONDecodeError) as e:\n",
    "        raise RuntimeError(f\"Invalid LLM output: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sample = \"HireVue provides a platform for digital interviewing, candidate screening, and interview analytics for HR teams.\"\n",
    "    result = check_desc(sample)\n",
    "    print(result.model_dump())\n",
    "\n",
    "# === 6. Apply LLM to DataFrame ===\n",
    "results = (\n",
    "    df_use[\"tool_description\"]\n",
    "    .apply(lambda desc: check_desc(desc).model_dump())\n",
    ")\n",
    "df_use[[\"relevant\", \"reason\"]] = results.apply(pd.Series)\n",
    "\n",
    "# Optional: inspect\n",
    "print(df_use.head())\n",
    "\n",
    "# === 7. Update use_aggregated column for the use case ===\n",
    "def _to_list(cell: str) -> list[str]:\n",
    "    \"\"\"Convert a ;‑separated string (or NaN) → list without blanks.\"\"\"\n",
    "    if pd.isna(cell):\n",
    "        return []\n",
    "    return [u.strip() for u in str(cell).split(\";\") if u.strip()]\n",
    "\n",
    "def update_use_aggregated(row):\n",
    "    uses = _to_list(row[\"use_aggregated\"])\n",
    "    if row[\"relevant\"]:\n",
    "        if TARGET_USE not in uses:\n",
    "            uses.append(TARGET_USE)\n",
    "    else:\n",
    "        uses = [u for u in uses if u != TARGET_USE]\n",
    "    prefix = \";\" if str(row[\"use_aggregated\"]).startswith(\";\") else \"\"\n",
    "    return prefix + \";\".join(uses)\n",
    "\n",
    "df_use[\"use_aggregated\"] = df_use.apply(update_use_aggregated, axis=1)\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df_use.to_excel(EXCEL_OUT, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d73db9e",
   "metadata": {},
   "source": [
    "## Validating compliance management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2dadca6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 354 entries, 53 to 19226\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   tool_id           354 non-null    int64 \n",
      " 1   use_original      279 non-null    object\n",
      " 2   use_aggregated    279 non-null    object\n",
      " 3   name_tool         354 non-null    object\n",
      " 4   tool_url_y        354 non-null    object\n",
      " 5   tool_description  354 non-null    object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 19.4+ KB\n",
      "{'relevant': False, 'reason': 'HireVue primarily focuses on digital interviewing and candidate screening, which are not directly related to compliance management.'}\n",
      "     tool_id                                       use_original  \\\n",
      "4        778  ;payroll management;compliance management;cont...   \n",
      "25      6748  ;cloud security & compliance;device management...   \n",
      "111      726  ;data visualization;machine learning;complianc...   \n",
      "144    13296  ;cloud applications & integrations;compliance ...   \n",
      "224    12077  ;content generation;learning analytics;learnin...   \n",
      "\n",
      "                                        use_aggregated   name_tool  \\\n",
      "4    payroll management;compliance management;contr...        Deel   \n",
      "25   ;cloud security & compliance;device management...  LambdaTest   \n",
      "111  data visualization;machine learning;compliance...    Cloudera   \n",
      "144  ;cloud applications & integrations;compliance ...      Pulumi   \n",
      "224  ;content generation;learning analytics;learnin...  Docebo LMS   \n",
      "\n",
      "         tool_url_y                                   tool_description  \\\n",
      "4          deel.com  Deel provides a comprehensive platform for glo...   \n",
      "25   lambdatest.com  LambdaTest offers a cloud-based platform enabl...   \n",
      "111    cloudera.com  Cloudera Data Platform provides a unified hybr...   \n",
      "144      pulumi.com  Pulumi offers infrastructure as code solutions...   \n",
      "224      docebo.com  The Docebo learning platform leverages AI to t...   \n",
      "\n",
      "     relevant                                             reason  \n",
      "4        True  Deel's platform includes compliance management...  \n",
      "25      False  LambdaTest primarily focuses on cross-browser ...  \n",
      "111      True  Cloudera Data Platform's focus on secure data ...  \n",
      "144      True  Pulumi's focus on security and compliance in i...  \n",
      "224      True  The Docebo learning platform includes complian...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lz/910twyk903nb6sxfgz54bngc0000gn/T/ipykernel_28883/6861976.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_use[[\"relevant\", \"reason\"]] = results.apply(pd.Series)\n",
      "/var/folders/lz/910twyk903nb6sxfgz54bngc0000gn/T/ipykernel_28883/6861976.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_use[[\"relevant\", \"reason\"]] = results.apply(pd.Series)\n",
      "/var/folders/lz/910twyk903nb6sxfgz54bngc0000gn/T/ipykernel_28883/6861976.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_use[\"use_aggregated\"] = df_use.apply(update_use_aggregated, axis=1)\n"
     ]
    }
   ],
   "source": [
    "# --- Modular pipeline for any use case (example: interviews & interview management) ---\n",
    "\n",
    "import os, json, openai\n",
    "from pydantic import BaseModel, ValidationError\n",
    "import pandas as pd\n",
    "\n",
    "# === 1. CONFIGURATION: Set your use case here ===\n",
    "USE_CASE = \"compliance management\"\n",
    "TARGET_USE = \"compliance management\"\n",
    "KEYWORDS = [\n",
    "    \"compliance\",\n",
    "    \"regulatory compliance\",\n",
    "    \"regulatory management\",\n",
    "    \n",
    "    \"regulatory audit\",\n",
    "\n",
    "    \"regulatory technology\",\n",
    "    \"regtech\",\n",
    "\n",
    "    \"risk & compliance\",\n",
    "\n",
    "    \n",
    "    \"legal compliance\",\n",
    "    \"compliance automation\",\n",
    "    \"compliance monitoring\",\n",
    "    \"compliance reporting\",\n",
    "    \"compliance risk\",\n",
    "    \"compliance requirements\",\n",
    "    \"compliance obligations\",\n",
    "    \"compliance audit\",\n",
    "\n",
    "    \n",
    "]\n",
    "EXCEL_OUT = \"compliance_management_cleaned.xlsx\"\n",
    "\n",
    "# === 2. Filter by keywords in 'use_aggregated' ===\n",
    "def filter_by_keywords(df, col, keywords):\n",
    "    \"\"\"Return rows where any keyword appears in the given column (case-insensitive).\"\"\"\n",
    "    pattern = \"|\".join([rf\"\\b{k}\\b\" for k in keywords])\n",
    "    return df[df[col].str.contains(pattern, case=False, na=False)]\n",
    "\n",
    "# Use your main DataFrame (replace as needed)\n",
    "df_use = filter_by_keywords(df_selected, 'use_aggregated', KEYWORDS)\n",
    "\n",
    "# === 3. Filter by keywords in 'tool_description' not already in df_use ===\n",
    "desc_df_all = filter_by_keywords(df_selected, 'tool_description', KEYWORDS)\n",
    "desc_df = desc_df_all[~desc_df_all['tool_id'].isin(df_use['tool_id'])]\n",
    "\n",
    "# Optional: inspect\n",
    "desc_df.info()\n",
    "\n",
    "# === 4. Save to Excel (filename parameterized) ===\n",
    "desc_df.to_excel(EXCEL_OUT, index=False)\n",
    "\n",
    "# === 5. LLM schema and function for this use case ===\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")       # keep your key outside code\n",
    "\n",
    "class UseCaseCheck(BaseModel):\n",
    "    relevant: bool\n",
    "    reason: str | None = None\n",
    "\n",
    "SYSTEM = \"You are a JSON‑only API. Respond via the function call.\"\n",
    "USER_TMPL = (\n",
    "    f\"Does this tool or company do *{USE_CASE}*, or is very closely related to this use case or business?\\n\\n\"\n",
    "    \"\\\"\\\"\\\"{desc}\\\"\\\"\\\"\"\n",
    ")\n",
    "\n",
    "def check_desc(desc: str) -> UseCaseCheck:\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": USER_TMPL.format(desc=desc)}\n",
    "        ],\n",
    "        functions=[{\n",
    "            \"name\": \"relevant\",\n",
    "            \"description\": f\"Return whether tool performs {USE_CASE}\",\n",
    "            \"parameters\": UseCaseCheck.model_json_schema()\n",
    "        }],\n",
    "        function_call={\"name\": \"relevant\"}\n",
    "    )\n",
    "    args_json = completion.choices[0].message.function_call.arguments\n",
    "    try:\n",
    "        return UseCaseCheck(**json.loads(args_json))\n",
    "    except (ValidationError, json.JSONDecodeError) as e:\n",
    "        raise RuntimeError(f\"Invalid LLM output: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sample = \"HireVue provides a platform for digital interviewing, candidate screening, and interview analytics for HR teams.\"\n",
    "    result = check_desc(sample)\n",
    "    print(result.model_dump())\n",
    "\n",
    "# === 6. Apply LLM to DataFrame ===\n",
    "results = (\n",
    "    df_use[\"tool_description\"]\n",
    "    .apply(lambda desc: check_desc(desc).model_dump())\n",
    ")\n",
    "df_use[[\"relevant\", \"reason\"]] = results.apply(pd.Series)\n",
    "\n",
    "# Optional: inspect\n",
    "print(df_use.head())\n",
    "\n",
    "# === 7. Update use_aggregated column for the use case ===\n",
    "def _to_list(cell: str) -> list[str]:\n",
    "    \"\"\"Convert a ;‑separated string (or NaN) → list without blanks.\"\"\"\n",
    "    if pd.isna(cell):\n",
    "        return []\n",
    "    return [u.strip() for u in str(cell).split(\";\") if u.strip()]\n",
    "\n",
    "def update_use_aggregated(row):\n",
    "    uses = _to_list(row[\"use_aggregated\"])\n",
    "    if row[\"relevant\"]:\n",
    "        if TARGET_USE not in uses:\n",
    "            uses.append(TARGET_USE)\n",
    "    else:\n",
    "        uses = [u for u in uses if u != TARGET_USE]\n",
    "    prefix = \";\" if str(row[\"use_aggregated\"]).startswith(\";\") else \"\"\n",
    "    return prefix + \";\".join(uses)\n",
    "\n",
    "df_use[\"use_aggregated\"] = df_use.apply(update_use_aggregated, axis=1)\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df_use.to_excel(EXCEL_OUT, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72279c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Market Overview & Trends  \n",
      "The generative **audio AI** market is small but growing explosively. A recent report pegs the global *enterprise* audio generative AI market at about **$219.7M in 2024**, with an astonishing ~**43.9% CAGR** through 2030 ([www.grandviewresearch.com](https://www.grandviewresearch.com/horizon/statistics/enterprise-generative-ai-market/model-type/audio/global#:~:text=The%20global%20audio%20enterprise%20generative,from%202024%20to%202030)).  (More broadly, combined audio+video AI content generation is forecast to grow from ~$25.9B in 2024 to $132.6B by 2030 ([virtuemarketresearch.com](https://virtuemarketresearch.com/report/audio-or-visual-generative-ai-market#:~:text=,of%20possibilities%20for%20different%20competitors)) – underscoring rapid adoption in media and entertainment.) This growth is driven by demand for scalable content: from automated music and soundtracks to lifelike voiceovers in e-learning, gaming, advertising, and virtual assistants. Major AI labs are racing to improve audio models (e.g. Nvidia’s new “Fugatto” generative audio transformer ([www.reuters.com](https://www.reuters.com/technology/artificial-intelligence/nvidia-shows-ai-model-that-can-modify-voices-generate-novel-sounds-2024-11-25/#:~:text=Nvidia%20has%20unveiled%20a%20new,Nvidia%20does%20not%20plan%20an))), while startups attract big funding (e.g. WaveForms AI raised $40M at a $200M valuation to build emotional AI voice agents ([www.reuters.com](https://www.reuters.com/technology/artificial-intelligence/former-openai-researcher-raises-40-million-build-more-empathetic-audio-ai-2024-12-09/#:~:text=Former%20OpenAI%20researcher%20Alexis%20Conneau,and%20Coralie%20Lemaitre%2C%20aims%20to))). Content creators and enterprises alike are using these tools to slash production costs and personalize media – Hollywood unions are even negotiating new contracts around AI voices (as seen in Replica’s deal with SAG-AFTRA) ([www.axios.com](https://www.axios.com/2024/01/09/actor-union-deal-ai-voice#:~:text=The%20Screen%20Actors%20Guild%20has,platform%2C%20setting)).  \n",
      "\n",
      "**Key trends:** AI-generated audio is moving from novelty to tooling. Efficient TTS and voice-cloning let UX designers, game studios and educators prototype dialogue rapidly. Meanwhile AI **music composition** tools are being adopted for commercials, game scores, and social-media content. Freemium models dominate consumer tools (e.g. LALAL.AI’s stem-splitter handles *30M+ audio jobs in 2023 ([www.lalal.ai](https://www.lalal.ai/blog/2023-wrapped/#:~:text=In%202023%2C%20LALAL,What%27s%20more%2C%20750%20new%20qualified))), while enterprise platforms (e.g. Descript, Synthesia) sell subscriptions to large organizations. The market is still evolving: ethical licensing and watermarking (as in Voicemod’s “Fairly Trained” badges ([cadenaser.com](https://cadenaser.com/nacional/2024/12/02/210-voces-y-4-millones-de-usuarios-la-startup-espanola-que-revoluciona-la-comunicacion-entre-jovenes-cadena-ser/#:~:text=Voicemod%2C%20una%20startup%20espa%C3%B1ola%20cofundada,ofrece%20una%20capa%20adicional%20de))) are drawing attention, even as venture investment pours in (ElevenLabs raised $180M at a $3.3B valuation this year, signaling strong investor faith). \n",
      "\n",
      "## Top Generative Audio AI Tools  \n",
      "\n",
      "### Epidemic Sound (Sweden)  \n",
      "- **Product:** Large library of *licensed* music tracks and sound effects for creators. (Not an AI composer per se, but its scale makes it a key audio content provider.)  \n",
      "- **Business model:** Subscription/licensing to content creators, YouTubers, TikTok users, advertisers, etc. You pay to cover royalties so videos stay cleared.  \n",
      "- **Metrics:** Hosts ~**40,000** curated soundtracks on its platform ([www.reuters.com](https://www.reuters.com/markets/deals/music-platform-epidemic-sound-eyeing-possible-2025-ipo-sources-say-2024-05-14/#:~:text=Epidemic%20Sound%20was%20valued%20at,growth%20in%20net)). In 2023 it reported *SEK 1.5 billion* (~$138M) in net sales — up 25% year-on-year ([www.reuters.com](https://www.reuters.com/markets/deals/music-platform-epidemic-sound-eyeing-possible-2025-ipo-sources-say-2024-05-14/#:~:text=Epidemic%20Sound%20was%20valued%20at,The%20music)). (It has been VC-backed and was valued ~$1.4B in 2021 ([www.reuters.com](https://www.reuters.com/markets/deals/music-platform-epidemic-sound-eyeing-possible-2025-ipo-sources-say-2024-05-14/#:~:text=advisors%20soon%20to%20prepare%20for,over%2040%2C000%20soundtracks%2C%20with%20significant)) and is eyeing a 2025 IPO.)  \n",
      "- **Notable use cases:** Background music for YouTube videos, podcasts and ads. (Its growth and IPO plans reflect strong demand for on-demand production-ready tracks.)  \n",
      "\n",
      "### Synthesia (UK)  \n",
      "- **Product:** AI video production platform. Takes text (or PPTs) and generates videos with **realistic talking avatars and voices**. Primarily aimed at corporate communications (training vids, explainer videos, etc).  \n",
      "- **Business model:** SaaS (monthly/enterprise licenses) for large organizations to create videos in-house. (No actor or studio needed.)  \n",
      "- **Metrics:** Recently closed a $180M funding round (Jan 2025) at a **$2.1B** valuation ([www.ft.com](https://www.ft.com/content/3a35f3ba-7273-41ea-a0a5-77fe46965e63#:~:text=UK%20artificial%20intelligence%20start,last%20year%20but%20also%20post)). In FY2023 it booked about **£25.7M** (~$31M) in revenue, but ran a comparable loss (~£23.6M) ([www.ft.com](https://www.ft.com/content/3a35f3ba-7273-41ea-a0a5-77fe46965e63#:~:text=from%20Google%20Ventures%20and%20Accel,challenge%20global%20AI%20rivals%20and)) (reflecting heavy reinvestment in R&D and sales). Synthesia claims tens of thousands of users; reports indicate its customer base includes most Fortune 100 firms, who use it for training and internal comms (Synthesia’s site brags “trusted by 90% of Fortune 100”).  \n",
      "- **Notable use cases:** Large enterprises generating localized training videos (e.g. translating one video into many languages instantly), sales demo videos using brand-consistent presenters, marketing explainers without on-camera shoot. The big funding and Fortune 100 traction show it’s now a leading enterprise “video avatar” solution.  \n",
      "\n",
      "### Cartesia (USA)  \n",
      "- **Product:** Real-time **voice AI** API for developers. Generates ultra-realistic speech on the fly (e.g. for phone calls, podcasts, games) using advanced state-space audio models. Emphasizes extremely low latency.  \n",
      "- **Business model:** Developer platform (pay-as-you-go/API). The site touts “**Trusted by 50K+ customers**” ([cartesia.ai](https://cartesia.ai/product/ai-voice-generator#:~:text=Talk%20to%20Sales)) – likely a mix of indie devs and businesses. There’s a free tier and paid subscription for higher volume.  \n",
      "- **Metrics:** Early-stage startup; no public revenue disclosed yet. (It launched ~2023.) Highlights: advertises “fastest, ultra-realistic voice” generation ([cartesia.ai](https://cartesia.ai/#:~:text=The%20fastest%2C%20ultra,AI%20platform)), aiming to replace expensive voice-actor recordings in apps.  \n",
      "- **Notable use cases:** Companies integrate Cartesia into voice assistants, interactive voice response systems, live-streaming (voice changers), and anything requiring on-demand speech generation. Its state-space models are tuned for “never pre-listening” contexts, making it suitable for live calls or gaming chat.  \n",
      "\n",
      "### Replica Studios (UK)  \n",
      "- **Product:** AI voice library and synthesis engine focused on *character voices* for games, animation, and interactive media. Offers a catalog of expressive voices that can be scripted.  \n",
      "- **Business model:** Cloud-based licensing or subscription for media producers. Emphasizes “ethical AI” – actors behind voices are paid royalties.  \n",
      "- **Metrics:** Not publicly disclosed, but spotlighted for its SAG-AFTRA agreement: in early 2024 SAG (actors’ union) struck a deal with Replica requiring consent and minimum pay when cloning a voice ([www.axios.com](https://www.axios.com/2024/01/09/actor-union-deal-ai-voice#:~:text=The%20Screen%20Actors%20Guild%20has,platform%2C%20setting)). This suggests Replica has enough use in games/films to set industry norms. No financials published.  \n",
      "- **Notable use cases:** Video game studios using fast voice replacements, film/animation pre-visualizations, audiobooks. (For example, game actors have used Replica to clone their own voices so they can delegate tedious recording tasks ([apnews.com](https://apnews.com/article/517cc248f60a2f5e35f9b239b70f20a7#:~:text=Video%20game%20actors%20are%20increasingly,as%20Sarah%20Elmaleh%20and%20Zeke)).) Replica’s SAG deal indicates it’s seen as a leader in responsible voice-cloning tools.  \n",
      "\n",
      "### AIVA (Luxembourg)  \n",
      "- **Product:** AI music composition. Users input style/parameters and AIVA generates original musical compositions (often orchestral/cinematic style) suitable for soundtracks. The AI was trained on classical music masters.  \n",
      "- **Business model:** Subscription/licensing. Composers or companies sign up to use the software and license resulting tracks royalty-free. Also partnerships (e.g. it was integrated with NetEase’s music platform).  \n",
      "- **Metrics:** Established 2016. Raised ~€2.15M by mid-2020 (including a €1.5M round led by China’s NetEase ([chronicle.lu](https://chronicle.lu/category/innovation/33086-lux-startup-aiva-raises-eur1-5m-from-chinese-internet-company-netease#:~:text=Luxembourg,of%20China%27s%20biggest%20internet%20companies))). Team remains small (~10 people). Usage stats aren’t public, but AIVA has produced music for game demos, ads, etc.  \n",
      "- **Notable use cases:** Indie game developers and advertisers use AIVA to generate background scores without hiring composers. It was among the first to get rights societies’ approval (e.g. recognized by composers’ guilds). Its focus is original score-generation rather than samples or loops.  \n",
      "\n",
      "### Voicemod (Spain)  \n",
      "- **Product:** Real-time **voice changer** and text-to-speech app for consumers, especially gamers. Users can sound like various characters or even create their own voice filters via AI.  \n",
      "- **Business model:** Freemium mobile/desktop app. Free users get basic voices; premium subscription unlocks hundreds of high-quality filters. Also sells custom voice packs, and SDK licensing for other apps.  \n",
      "- **Metrics:** Founded ~2014. As of late 2024, the company reports **~4 million global users** and “210+ voices available” ([cadenaser.com](https://cadenaser.com/nacional/2024/12/02/210-voces-y-4-millones-de-usuarios-la-startup-espanola-que-revoluciona-la-comunicacion-entre-jovenes-cadena-ser/#:~:text=Voicemod%2C%20una%20startup%20espa%C3%B1ola%20cofundada,ofrece%20una%20capa%20adicional%20de)). (In Feb 2023 it raised about $14.5M from VCs, indicating solid growth.) It claims its AI runs in milliseconds to work live.  \n",
      "- **Notable use cases:** Young gamers and streamers (on Discord, Twitch etc.) using Voicemod to add humor or creativity to voice chat. Also used in short-form social media audio. Its rapid adoption and VC backing show strong consumer interest in playful AI voice tools.  \n",
      "\n",
      "### Descript (USA)  \n",
      "- **Product:** All-in-one audio/video editor that uses text as the editing interface. Key AI features include *Overdub* (ability to clone a user’s voice) and filler-word removal. Essentially, editing a podcast/video is as easy as editing a document transcript.  \n",
      "- **Business model:** SaaS tiers (from individual to enterprise); metered usage on premium features. Also sells enterprise licenses to media companies and educators.  \n",
      "- **Metrics:** Founded 2017 (ex-Groupon CEO Andrew Mason’s startup). As of 2021, customers included major media (e.g. Washington Post, NYT) ([techcrunch.com](https://techcrunch.com/2022/11/15/ai-powered-media-editing-app-descript-lands-fresh-cash-from-openai/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAJHrid8KmpRuVAWW28EwLSmLM4woyjOepcwQpf0dlMUnMyTx5PzM1CyyS7qM2vM_j40NEQ9L3__UDo3vsbM8_vgmXilABp6sJzwJ34u6p2hnyzDtBcSVSxvSDzSfRwRPejTuYYUVx65Wp4RQ7YpXzdhYt76rbwruMmaqval_66wI#:~:text=The%20Washington%20Post%20and%20The,organizations%20in%20the%20public%20sector)). In late 2022 it secured a big round led by OpenAI’s startup fund which reportedly valued Descript at ~$550M ([techcrunch.com](https://techcrunch.com/2022/11/15/ai-powered-media-editing-app-descript-lands-fresh-cash-from-openai/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAJHrid8KmpRuVAWW28EwLSmLM4woyjOepcwQpf0dlMUnMyTx5PzM1CyyS7qM2vM_j40NEQ9L3__UDo3vsbM8_vgmXilABp6sJzwJ34u6p2hnyzDtBcSVSxvSDzSfRwRPejTuYYUVx65Wp4RQ7YpXzdhYt76rbwruMmaqval_66wI#:~:text=report%20from%20The%20Information%20in,260%20million)). (That implies revenue on the order of tens of millions per year; Mason hinted at rapidly growing enterprise accounts.)  \n",
      "- **Notable use cases:** Podcasters, journalists and creators editing interviews; corporate trainers making screencasts; educational content developers. The fact that legacy outlets use Descript shows it’s professional-grade. Its voice-cloning is often used to fix mistakes in recordings by “retyping” missing words.  \n",
      "\n",
      "### LALAL.AI (Estonia)  \n",
      "- **Product:** AI-powered *vocal/instrumental separator*. Upload any song, and it spits out isolated stems (e.g. lead vocals, drums, bass, etc.) using advanced neural networks.  \n",
      "- **Business model:** Freemium credit system. Users get some free minutes; heavier users pay per minute or via subscription (starting around ~$15). No software install needed – all web-based.  \n",
      "- **Metrics:** Hit critical mass in 2023: **7 million new users** joined that year, and the service processed ~**30 million full audio splits** ([www.lalal.ai](https://www.lalal.ai/blog/2023-wrapped/#:~:text=In%202023%2C%20LALAL,What%27s%20more%2C%20750%20new%20qualified)). (It also boasts 750 affiliate partners ([www.lalal.ai](https://www.lalal.ai/blog/2023-wrapped/#:~:text=turned%20to%20LALAL,AI%20affiliate%20program)).) These numbers make it an industry leader in AI stem separation.  \n",
      "- **Notable use cases:** Karaoke/dj enthusiasts isolating vocals or instruments; remixers and producers repurposing original tracks; podcasters removing background music; educators creating music demos. LALAL.AI’s leading accuracy and speed (faster than many rivals) make it a go-to tool for content creators needing clean stems.  \n",
      "\n",
      "### Murf AI (India/USA)  \n",
      "- **Product:** Cloud platform for **AI voiceovers**. Offers ~120+ realistic voices in 22+ languages, plus custom voice cloning. Targets businesses creating narrated videos and presentations. Also has an “AI dubbing” service to localize video scripts automatically.  \n",
      "- **Business model:** Subscription-based (tiered by usage limits). Also enterprise licensing for larger teams.  \n",
      "- **Metrics:** Founded 2020. Raised **$10M Series A** in Sept 2022 (led by Matrix Partners India) ([murf.ai](https://murf.ai/blog/series-a-announcement#:~:text=We%20are%20excited%20to%20share,a%20new%20chapter%20for%20us)). The company reports **22× growth** year-over-year and over **1 million projects** generated on platform ([murf.ai](https://murf.ai/blog/series-a-announcement#:~:text=Murf%20AI%20raised%20%2410M%20in,globally%20and%20enhance%20its%20offerings)). This suggests Murf has moved well beyond prototypes into widespread use.  \n",
      "- **Notable use cases:** L&D and marketing teams converting training modules or slideshows into narrated videos, localizing content into multiple languages quickly, producing audiobooks. Clients include Fortune 500 firms and e-learning companies. Its high project count and VC backing indicate Murf is a mainstream voiceover platform for corporate media.  \n",
      "\n",
      "### Resemble AI (Canada/USA)  \n",
      "- **Product:** API-driven speech synthesis/clone. Users can create ultra-realistic voices (with emotions and cadences) either from text or by cloning a short sample. Offers both TTS and real-time voice dialogue.  \n",
      "- **Business model:** B2B SaaS/API licensing. Customers embed Resemble’s tech into products (e.g. chatbots, games, accessibility apps). Charges by voicehour or subscription.  \n",
      "- **Metrics:** Canada/U.S.-based, founded 2018. Raised **$8M Series A** in July 2023 (led by Javelin Ventures) ([www.seedtable.com](https://www.seedtable.com/startups/Resemble_AI-BWJE69M#:~:text=Recent%20Funding%20Rounds)). CEO reports ~**1 million registered users** (largely individuals cloning their own voice) and **200+ business clients** ([www.thestar.com.my](https://www.thestar.com.my/tech/tech-news/2023/07/12/voice-cloning-startup-resemble-ai-raises-8-million-in-series-a#:~:text=match%20at%20L22%20Resemble%20AI%2C,CEO%20Zohaib%20Ahmed%20told%20Reuters)). These clients span music producers, game studios and voice actors. (So far it’s a mid-stage startup with strong early adoption in both consumer demo and enterprise pilot uses.)  \n",
      "- **Notable use cases:** Automated IVR voice agents for companies, in-game NPC dialogue, voice assistants, and creative projects (e.g. an indie filmmaker voice-cloning actors for ADR).  It distinguishes itself by focusing on emotional nuance and security (watermarking outputs). The recent funding round underscores investor belief in a broad market for voice cloning APIs.\n",
      "\n",
      "Each of these companies occupies a distinct niche – from *music libraries* (Epidemic) to *video avatars* (Synthesia) to *voice modulation* (Voicemod) – but all are betting on AI to make audio creation faster, cheaper and more scalable. The strong growth figures and funding rounds above show why investors and strategists are watching this space: the ability to generate high-quality audio on demand is transforming media production pipelines, and companies that master the best models and distribution may capture substantial new value.  \n",
      "\n",
      "**Sources:** Industry reports and news (GrandView, Reuters, etc.) and company statements/publications ([www.grandviewresearch.com](https://www.grandviewresearch.com/horizon/statistics/enterprise-generative-ai-market/model-type/audio/global#:~:text=The%20global%20audio%20enterprise%20generative,from%202024%20to%202030)) ([www.reuters.com](https://www.reuters.com/markets/deals/music-platform-epidemic-sound-eyeing-possible-2025-ipo-sources-say-2024-05-14/#:~:text=Epidemic%20Sound%20was%20valued%20at,The%20music)) ([www.ft.com](https://www.ft.com/content/3a35f3ba-7273-41ea-a0a5-77fe46965e63#:~:text=UK%20artificial%20intelligence%20start,challenge%20global%20AI%20rivals%20and)) ([www.axios.com](https://www.axios.com/2024/01/09/actor-union-deal-ai-voice#:~:text=The%20Screen%20Actors%20Guild%20has,platform%2C%20setting)) ([www.lalal.ai](https://www.lalal.ai/blog/2023-wrapped/#:~:text=In%202023%2C%20LALAL,What%27s%20more%2C%20750%20new%20qualified)) ([murf.ai](https://murf.ai/blog/series-a-announcement#:~:text=We%20are%20excited%20to%20share,a%20new%20chapter%20for%20us)) ([murf.ai](https://murf.ai/blog/series-a-announcement#:~:text=Murf%20AI%20raised%20%2410M%20in,globally%20and%20enhance%20its%20offerings)) ([www.seedtable.com](https://www.seedtable.com/startups/Resemble_AI-BWJE69M#:~:text=Recent%20Funding%20Rounds)) ([www.thestar.com.my](https://www.thestar.com.my/tech/tech-news/2023/07/12/voice-cloning-startup-resemble-ai-raises-8-million-in-series-a#:~:text=match%20at%20L22%20Resemble%20AI%2C,CEO%20Zohaib%20Ahmed%20told%20Reuters)), as cited above. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Voorbeeld: Deep research prompt voor audio generation tools, met top 10 tools\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(timeout=3600)\n",
    "\n",
    "# Stel de top 10 audio generation tools samen (voorbeeldnamen, vervang door echte top 10 indien beschikbaar)\n",
    "top_10_audio_tools = [\n",
    "    \"Epidemic Sound\",\n",
    "    \"Synthesia\",\n",
    "    \"Cartesia\",\n",
    "    \"Replica Studios\",\n",
    "    \"Aiva\",\n",
    "    \"Voicemod\",\n",
    "    \"Descript\",\n",
    "    \"LALAL.AI\",\n",
    "    \"Murf AI\",\n",
    "    \"Resemble AI\"\n",
    "]\n",
    "\n",
    "tools_list_str = \"\\n\".join([f\"- {tool}\" for tool in top_10_audio_tools])\n",
    "\n",
    "input_text = f\"\"\"\n",
    "Research the current landscape and future trends of audio generation AI tools, with a focus on the top 10 tools in the market:\n",
    "{tools_list_str}\n",
    "\n",
    "Do:\n",
    "- Include specific figures, market size, growth rates, and notable use cases.\n",
    "- For each of the top 10 tools, provide a brief summary of their product, business model, and any available usage or financial metrics.\n",
    "- Prioritize reliable, up-to-date sources: peer-reviewed research, industry reports, tech news, or company financials.\n",
    "- Include inline citations and return all source metadata.\n",
    "\n",
    "Be analytical, avoid generalities, and ensure that each section supports\n",
    "data-backed reasoning that could inform product strategy or investment decisions.\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "  model=\"o4-mini-deep-research\",\n",
    "  input=input_text,\n",
    "  tools=[\n",
    "    {\"type\": \"web_search_preview\"},\n",
    "    {\"type\": \"code_interpreter\", \"container\": {\"type\": \"auto\"}},\n",
    "  ],\n",
    ")\n",
    "\n",
    "print(response.output_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3018b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analyzing duplicate tools issue\n",
    "\n",
    "# Check how many unique tool_ids we have vs total entries\n",
    "print(\"=== DUPLICATE ANALYSIS ===\")\n",
    "print(f\"Total entries: {len(df_selected)}\")\n",
    "print(f\"Unique tool_ids: {df_selected['tool_id'].nunique()}\")\n",
    "print(f\"Duplicate entries: {len(df_selected) - df_selected['tool_id'].nunique()}\")\n",
    "\n",
    "# Find tools that appear multiple times\n",
    "duplicate_tool_ids = df_selected['tool_id'].value_counts()\n",
    "duplicates = duplicate_tool_ids[duplicate_tool_ids > 1]\n",
    "\n",
    "print(f\"\\nNumber of tools that appear multiple times: {len(duplicates)}\")\n",
    "print(f\"Most duplicated tool appears {duplicates.max()} times\")\n",
    "\n",
    "# Show examples of duplicated tools\n",
    "print(\"\\n=== EXAMPLES OF DUPLICATED TOOLS ===\")\n",
    "for tool_id in duplicates.head(5).index:\n",
    "    print(f\"\\nTool ID {tool_id} appears {duplicates[tool_id]} times:\")\n",
    "    tool_rows = df_selected[df_selected['tool_id'] == tool_id]\n",
    "    for idx, row in tool_rows.iterrows():\n",
    "        print(f\"  Row {idx}: {row['name_tool']} - use_original: {row['use_original']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84355295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the duplicates have different use_original values (which would explain why they exist)\n",
    "print(\"=== CHECKING WHY DUPLICATES EXIST ===\")\n",
    "\n",
    "# For each duplicated tool, check if the use_original values differ\n",
    "for tool_id in duplicates.head(10).index:\n",
    "    tool_rows = df_selected[df_selected['tool_id'] == tool_id]\n",
    "    use_original_values = tool_rows['use_original'].dropna().unique()\n",
    "    use_aggregated_values = tool_rows['use_aggregated'].dropna().unique()\n",
    "    \n",
    "    print(f\"\\nTool ID {tool_id} ({tool_rows.iloc[0]['name_tool']}):\")\n",
    "    print(f\"  Different use_original values: {len(use_original_values)}\")\n",
    "    print(f\"  Different use_aggregated values: {len(use_aggregated_values)}\")\n",
    "    \n",
    "    if len(use_original_values) > 1:\n",
    "        print(f\"  use_original values: {list(use_original_values)}\")\n",
    "    if len(use_aggregated_values) > 1:\n",
    "        print(f\"  use_aggregated values: {list(use_aggregated_values)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c27bf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1eae11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bff7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1: Remove exact duplicates (same tool_id AND same use_original)\n",
    "print(\"=== SOLUTION OPTIONS ===\")\n",
    "\n",
    "# Check for exact duplicates\n",
    "exact_duplicates = df_selected.duplicated(subset=['tool_id', 'use_original'], keep='first')\n",
    "print(f\"Exact duplicates (same tool_id + use_original): {exact_duplicates.sum()}\")\n",
    "\n",
    "# Solution 1: Keep only unique combinations of tool_id + use_original\n",
    "df_deduplicated = df_selected.drop_duplicates(subset=['tool_id', 'use_original'], keep='first')\n",
    "print(f\"After removing exact duplicates: {len(df_deduplicated)} entries\")\n",
    "\n",
    "# Solution 2: Keep only one record per tool_id (first occurrence)\n",
    "df_one_per_tool = df_selected.drop_duplicates(subset=['tool_id'], keep='first')\n",
    "print(f\"After keeping only one record per tool: {len(df_one_per_tool)} entries\")\n",
    "\n",
    "# Solution 3: Aggregate multiple records per tool into one record\n",
    "print(\"\\n=== AGGREGATION APPROACH ===\")\n",
    "# Group by tool_id and combine use_original values\n",
    "def combine_uses(series):\n",
    "    # Remove NaN values and combine unique values\n",
    "    values = series.dropna().astype(str)\n",
    "    unique_values = []\n",
    "    for val in values:\n",
    "        # Split by semicolon and add to unique list\n",
    "        for item in val.split(';'):\n",
    "            item = item.strip()\n",
    "            if item and item not in unique_values:\n",
    "                unique_values.append(item)\n",
    "    return ';'.join(unique_values)\n",
    "\n",
    "df_aggregated = df_selected.groupby('tool_id').agg({\n",
    "    'name_tool': 'first',\n",
    "    'tool_url_y': 'first', \n",
    "    'tool_description': 'first',\n",
    "    'use_original': combine_uses,\n",
    "    'use_aggregated': combine_uses\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"After aggregating by tool_id: {len(df_aggregated)} entries\")\n",
    "print(f\"This gives us exactly {df_selected['tool_id'].nunique()} unique tools\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc43ad15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_aggregated is not defined, using df_deduplicated instead.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_deduplicated' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lz/910twyk903nb6sxfgz54bngc0000gn/T/ipykernel_28883/3403756478.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf_audio_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_aggregated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_aggregated' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lz/910twyk903nb6sxfgz54bngc0000gn/T/ipykernel_28883/3403756478.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"df_aggregated is not defined, using df_deduplicated instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdf_audio_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_deduplicated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"audio\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_audio_source\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_deduplicated' is not defined"
     ]
    }
   ],
   "source": [
    "# Select top 10 audio generation tools\n",
    "# (Assume 'audio' is a boolean column indicating audio generation tools, as in previous cells)\n",
    "\n",
    "# Use df_aggregated if defined, otherwise fall back to df_deduplicated\n",
    "try:\n",
    "    df_audio_source = df_aggregated\n",
    "except NameError:\n",
    "    print(\"df_aggregated is not defined, using df_deduplicated instead.\")\n",
    "    df_audio_source = df_deduplicated\n",
    "\n",
    "if \"audio\" not in df_audio_source.columns:\n",
    "    # If not present, try to infer from use_aggregated\n",
    "    df_audio_source[\"audio\"] = df_audio_source[\"use_aggregated\"].str.contains(\"audio generation\", case=False, na=False)\n",
    "\n",
    "audio_tools = df_audio_source[df_audio_source[\"audio\"] == True].copy()\n",
    "top10_audio_tools = audio_tools.head(10)\n",
    "\n",
    "# Prepare data for API call: convert to dicts (records)\n",
    "audio_tools_payload = top10_audio_tools.to_dict(orient=\"records\")\n",
    "\n",
    "import requests\n",
    "\n",
    "# Example API endpoint for o4-mini-deep-research (replace with actual endpoint if different)\n",
    "api_url = \"https://o4-mini-deep-research/api/tools\"\n",
    "\n",
    "# Make the API call (POST) with all variables for the top 10 audio generation tools\n",
    "response = requests.post(api_url, json={\"tools\": audio_tools_payload})\n",
    "\n",
    "# Print response status and content\n",
    "print(\"API response status:\", response.status_code)\n",
    "try:\n",
    "    print(\"API response content:\", response.json())\n",
    "except Exception as e:\n",
    "    print(\"Could not decode JSON response:\", e)\n",
    "    print(\"Raw response content:\", response.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
